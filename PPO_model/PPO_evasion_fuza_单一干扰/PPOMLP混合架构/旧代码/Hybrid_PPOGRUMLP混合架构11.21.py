# --- START OF FILE Hybrid_PPO_jsbsim_SeparateHeads.py ---

import torch
from torch.nn import *
from torch.distributions import Bernoulli, Categorical
from torch.distributions import Normal
# å¯¼å…¥é…ç½®æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«å„ç§è¶…å‚æ•°
from Interference_code.PPO_model.PPO_evasion_fuza.ConfigGRU import *
# å¯¼å…¥æ”¯æŒ GRU çš„ç»éªŒå›æ”¾æ± 
from Interference_code.PPO_model.PPO_evasion_fuza.BufferGRU import *
from torch.optim import lr_scheduler
import numpy as np
import os
import re
import time
# å¯¼å…¥ PyTorch çš„è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒå·¥å…·ï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒå¹¶å‡å°‘æ˜¾å­˜å ç”¨
from torch.cuda.amp import GradScaler, autocast

# --- åŠ¨ä½œç©ºé—´é…ç½® (ä¸åŸç‰ˆç›¸åŒ) ---
# å®šä¹‰è¿ç»­åŠ¨ä½œçš„ç»´åº¦å’Œé”®å
CONTINUOUS_DIM = 4
CONTINUOUS_ACTION_KEYS = ['throttle', 'elevator', 'aileron', 'rudder']
# å®šä¹‰ç¦»æ•£åŠ¨ä½œçš„ç»´åº¦ã€‚æ¯ä¸ªé”®ä»£è¡¨ä¸€ä¸ªç¦»æ•£å†³ç­–ï¼Œå€¼ä»£è¡¨è¯¥å†³ç­–æœ‰å¤šå°‘ä¸ªé€‰é¡¹ã€‚
DISCRETE_DIMS = {
    'flare_trigger': 1,  # å¹²æ‰°å¼¹è§¦å‘ï¼Œä¼¯åŠªåˆ©åˆ†å¸ƒ (æ˜¯/å¦)ï¼Œæ‰€ä»¥æ˜¯1ä¸ª logit
    'salvo_size': 3,  # é½å°„æ•°é‡ï¼Œ3ä¸ªé€‰é¡¹
    # 'intra_interval': 3,  # ç»„å†…é—´éš”ï¼Œ3ä¸ªé€‰é¡¹
    'num_groups': 3,  # ç»„æ•°ï¼Œ3ä¸ªé€‰é¡¹
    'inter_interval': 3,  # ç»„é—´é—´éš”ï¼Œ3ä¸ªé€‰é¡¹
}
# è®¡ç®—æ‰€æœ‰ç¦»æ•£åŠ¨ä½œ logits çš„æ€»ç»´åº¦
TOTAL_DISCRETE_LOGITS = sum(DISCRETE_DIMS.values())
# è®¡ç®—å­˜å‚¨åœ¨ Buffer ä¸­çš„æ€»åŠ¨ä½œç»´åº¦ï¼ˆè¿ç»­åŠ¨ä½œ + ç¦»æ•£åŠ¨ä½œçš„ç±»åˆ«ç´¢å¼•ï¼‰
TOTAL_ACTION_DIM_BUFFER = CONTINUOUS_DIM + len(DISCRETE_DIMS)
# ç¦»æ•£åŠ¨ä½œçš„ç±»åˆ«ç´¢å¼•åˆ°å®é™…ç‰©ç†å€¼çš„æ˜ å°„
DISCRETE_ACTION_MAP = {
    # 'salvo_size': [2, 4, 6],
    # 'intra_interval': [0.02, 0.04, 0.1],
    # 'num_groups': [1, 2, 3],
    # 'inter_interval': [0.5, 1.0, 2.0]
    # 'salvo_size': [1, 2, 3],  # ä¿®æ”¹ä¸ºå‘å°„1ã€2ã€3æš
    # # 'intra_interval': [0.05, 0.1, 0.15],
    # 'intra_interval': [0.02, 0.04, 0.08],
    # 'num_groups': [1, 2, 3],
    # 'inter_interval': [0.2, 0.5, 1.0]
    'salvo_size': [2, 3, 4],  # ä¿®æ”¹ä¸ºå‘å°„2ã€3ã€4æš
    # 'intra_interval': [0.05, 0.1, 0.15],
    # 'intra_interval': [0.02, 0.04, 0.06],
    'num_groups': [2, 3, 4],
    'inter_interval': [0.2, 0.4, 0.6]
}
# è¿ç»­åŠ¨ä½œçš„ç‰©ç†èŒƒå›´ï¼Œç”¨äºå°†ç½‘ç»œè¾“å‡º (-1, 1) ç¼©æ”¾åˆ°å®é™…èŒƒå›´
ACTION_RANGES = {
    'throttle': {'low': 0.0, 'high': 1.0},
    'elevator': {'low': -1.0, 'high': 1.0},
    'aileron': {'low': -1.0, 'high': 1.0},
    'rudder': {'low': -1.0, 'high': 1.0},
}

# <<< GRU/RNN ä¿®æ”¹ >>>: æ–°å¢ RNN é…ç½®
# è¿™äº›å‚æ•°æœ€å¥½ä¹Ÿç§»åˆ° Config.py ä¸­
RNN_HIDDEN_SIZE =  64 #128 #64 #9 #9 #32 #9  # GRU å±‚çš„éšè—å•å…ƒæ•°é‡
SEQUENCE_LENGTH =  15 #5 #5 #5 #10 #5 #5 #10  # è®­ç»ƒæ—¶ä»ç»éªŒæ± ä¸­é‡‡æ ·çš„è¿ç»­è½¨è¿¹ç‰‡æ®µçš„é•¿åº¦


# ==============================================================================
# <<< æ–°æ¶æ„ >>>: å®šä¹‰åŸºäº Encoder -> GRU -> Shared MLP çš„ Actor
#                       [ğŸ’¥ æ–°ç»“æ„: ç¼–ç å±‚ -> GRU -> å…±äº«MLP -> å¡”æ¥¼MLP -> Heads]
# ==============================================================================

class Actor_GRU(Module):
    """
    Actor ç½‘ç»œ (ç­–ç•¥ç½‘ç»œ) - [æ··åˆæ¶æ„: Encoder -> GRU -> Shared MLP]
    ç»“æ„ä¸º: ç¼–ç å±‚ -> GRU åºåˆ—å¤„ç† -> å…±äº«MLPåŸºåº§ -> ä¸“ç”¨MLPå¡”æ¥¼ -> ç‹¬ç«‹åŠ¨ä½œå¤´ã€‚
    """

    def __init__(self):
        super(Actor_GRU, self).__init__()
        self.input_dim = ACTOR_PARA.input_dim
        self.log_std_min = -20.0
        self.log_std_max = 2.0
        self.rnn_hidden_size = RNN_HIDDEN_SIZE

        # # --- 1. [æ–°å¢] ç¼–ç å±‚ (Encoder) ---
        # # å°†åŸå§‹è¾“å…¥æ˜ å°„åˆ° RNN çš„éšè—å±‚ç»´åº¦
        # self.encoder = Sequential(
        #     Linear(self.input_dim, self.rnn_hidden_size),
        #     LeakyReLU()
        # )

        # # --- [ä¿®æ”¹å]ï¼šåŒå±‚ + Tanh ---
        # enc_mid_dim = RNN_HIDDEN_SIZE * 2  # æˆ–è€… self.input_dim * 2
        # self.encoder = Sequential(
        #     Linear(self.input_dim, enc_mid_dim),
        #     LeakyReLU(),
        #     Linear(enc_mid_dim, self.rnn_hidden_size),
        #     # Tanh()  # <--- å…³é”®ä¿æŠ¤
        # )

        # # --- 2. GRU å±‚ ---
        # # è¾“å…¥å’Œè¾“å‡ºç»´åº¦éƒ½ä¿æŒä¸º rnn_hidden_size
        # self.gru = GRU(self.rnn_hidden_size, self.rnn_hidden_size, batch_first=True)
        # 2. GRU è¾“å…¥ç»´åº¦ç›´æ¥è®¾ä¸º input_dim
        self.gru = GRU(self.input_dim, self.rnn_hidden_size, batch_first=True)

        # --- 3. [ç§»åŠ¨] å…±äº« MLP åŸºåº§ (Shared MLP) ---
        # GRU çš„è¾“å‡ºè¿›å…¥æ­¤å…±äº«å±‚ã€‚æˆ‘ä»¬ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‰å‡ å±‚ä½œä¸ºå…±äº«å±‚ã€‚
        # å‡è®¾ model_layer_dim = [256, 256, 256]ï¼Œæˆ‘ä»¬ç”¨å‰2å±‚åšå…±äº«ï¼Œæœ€å1å±‚åšå¡”æ¥¼
        shared_layer_count = 2
        shared_dims = ACTOR_PARA.model_layer_dim[:shared_layer_count]

        self.shared_mlp = Sequential()
        input_dim = self.rnn_hidden_size
        for i, dim in enumerate(shared_dims):
            self.shared_mlp.add_module(f'shared_fc_{i}', Linear(input_dim, dim))
            self.shared_mlp.add_module(f'shared_leakyrelu_{i}', LeakyReLU())
            input_dim = dim

        shared_output_dim = shared_dims[-1] if shared_dims else self.rnn_hidden_size

        # --- 4. ä¸“ç”¨ MLP å¡”æ¥¼ (Post-Shared Towers) ---
        # å‰©ä½™çš„å±‚ä½œä¸ºç‹¬ç«‹å¡”æ¥¼
        tower_dims = ACTOR_PARA.model_layer_dim[shared_layer_count:]

        # è¿ç»­åŠ¨ä½œå¡”æ¥¼
        self.continuous_tower = Sequential()
        tower_input_dim = shared_output_dim
        for i, dim in enumerate(tower_dims):
            self.continuous_tower.add_module(f'cont_tower_fc_{i}', Linear(tower_input_dim, dim))
            self.continuous_tower.add_module(f'cont_tower_leakyrelu_{i}', LeakyReLU())
            tower_input_dim = dim
        continuous_tower_output_dim = tower_dims[-1] if tower_dims else shared_output_dim

        # ç¦»æ•£åŠ¨ä½œå¡”æ¥¼
        self.discrete_tower = Sequential()
        tower_input_dim = shared_output_dim
        for i, dim in enumerate(tower_dims):
            self.discrete_tower.add_module(f'disc_tower_fc_{i}', Linear(tower_input_dim, dim))
            self.discrete_tower.add_module(f'disc_tower_leakyrelu_{i}', LeakyReLU())
            tower_input_dim = dim
        discrete_tower_output_dim = tower_dims[-1] if tower_dims else shared_output_dim

        # --- 5. å®šä¹‰æœ€ç»ˆçš„è¾“å‡ºå¤´ (Heads) ---
        self.mu_head = Linear(continuous_tower_output_dim, CONTINUOUS_DIM)
        self.discrete_head = Linear(discrete_tower_output_dim, TOTAL_DISCRETE_LOGITS)
        self.log_std_param = torch.nn.Parameter(torch.full((1, CONTINUOUS_DIM), 0.0))

        # --- åˆå§‹åŒ–æƒé‡ ---
        self.apply(init_weights)

        # --- 6. ä¼˜åŒ–å™¨è®¾ç½® ---
        gru_params = list(self.gru.parameters())
        # æ”¶é›†æ‰€æœ‰é GRU å‚æ•°
        other_params = (
                # list(self.encoder.parameters()) +
                list(self.shared_mlp.parameters()) +
                list(self.continuous_tower.parameters()) +
                list(self.discrete_tower.parameters()) +
                list(self.mu_head.parameters()) +
                list(self.discrete_head.parameters()) +
                [self.log_std_param]
        )

        param_groups = [
            {'params': gru_params, 'lr': ACTOR_PARA.gru_lr},
            {'params': other_params, 'lr': ACTOR_PARA.lr}
        ]
        self.optim = torch.optim.Adam(param_groups)
        self.actor_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
                                                     end_factor=AGENTPARA.mini_lr / ACTOR_PARA.lr,
                                                     total_iters=AGENTPARA.MAX_EXE_NUM)
        self.to(ACTOR_PARA.device)

    def forward(self, obs, hidden_state):
        obs_tensor = check(obs).to(**ACTOR_PARA.tpdv)
        is_sequence = obs_tensor.dim() == 3
        if not is_sequence:
            obs_tensor = obs_tensor.unsqueeze(1)

        # # 1. [æ–°] é€šè¿‡ç¼–ç å±‚
        # # è¾“å…¥: (batch, seq_len, input_dim) -> è¾“å‡º: (batch, seq_len, rnn_hidden_size)
        # encoded_features = self.encoder(obs_tensor)

        # 2. é€šè¿‡ GRU
        # è¾“å…¥: (batch, seq_len, rnn_hidden_size) -> è¾“å‡º: (batch, seq_len, rnn_hidden_size)
        # gru_out, new_hidden = self.gru(encoded_features, hidden_state)
        gru_out, new_hidden = self.gru(obs_tensor, hidden_state)

        # 3. [æ–°] é€šè¿‡å…±äº« MLP
        # è¾“å…¥: (batch, seq_len, rnn_hidden_size) -> è¾“å‡º: (batch, seq_len, shared_output_dim)
        shared_features = self.shared_mlp(gru_out)

        # 4. å…±äº«ç‰¹å¾åˆ†åˆ«è¿›å…¥ä¸“ç”¨å¡”æ¥¼
        continuous_features = self.continuous_tower(shared_features)
        discrete_features = self.discrete_tower(shared_features)

        # 5. å¦‚æœæ˜¯å•æ­¥è¾“å…¥ï¼Œå‹ç¼©ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…å¤´éƒ¨
        if not is_sequence:
            continuous_features = continuous_features.squeeze(1)
            discrete_features = discrete_features.squeeze(1)

        # 6. è¾“å‡ºå¤´
        mu = self.mu_head(continuous_features)
        all_disc_logits = self.discrete_head(discrete_features)

        # --- ä»¥ä¸‹é€»è¾‘ä¿æŒä¸å˜ ---
        split_sizes = list(DISCRETE_DIMS.values())
        logits_parts = torch.split(all_disc_logits, split_sizes, dim=-1)
        trigger_logits, salvo_size_logits, num_groups_logits, inter_interval_logits = logits_parts

        has_flares_info = obs_tensor[..., 9]
        mask = (has_flares_info == 0)
        trigger_logits_masked = trigger_logits.clone()
        if torch.any(mask):
            if mask.dim() < trigger_logits_masked.dim():
                mask = mask.unsqueeze(-1)
            trigger_logits_masked[mask] = torch.finfo(torch.float32).min

        trigger_probs = torch.sigmoid(trigger_logits_masked)
        no_trigger_mask = (trigger_probs < 0.5).squeeze(-1)
        salvo_size_logits_masked = salvo_size_logits.clone()
        num_groups_logits_masked = num_groups_logits.clone()
        inter_interval_logits_masked = inter_interval_logits.clone()
        if torch.any(no_trigger_mask):
            INF = 1e6
            NEG_INF = -1e6
            for logits_tensor in [salvo_size_logits_masked, num_groups_logits_masked, inter_interval_logits_masked]:
                logits_sub = logits_tensor[no_trigger_mask]
                if logits_sub.numel() > 0:
                    logits_sub[:] = NEG_INF
                    logits_sub[:, 0] = INF
                    logits_tensor[no_trigger_mask] = logits_sub

        log_std = torch.clamp(self.log_std_param, self.log_std_min, self.log_std_max)
        std = torch.exp(log_std).expand_as(mu)
        continuous_base_dist = Normal(mu, std)

        trigger_dist = Bernoulli(logits=trigger_logits_masked.squeeze(-1))
        salvo_size_dist = Categorical(logits=salvo_size_logits_masked)
        num_groups_dist = Categorical(logits=num_groups_logits_masked)
        inter_interval_dist = Categorical(logits=inter_interval_logits_masked)

        distributions = {
            'continuous': continuous_base_dist,
            'trigger': trigger_dist,
            'salvo_size': salvo_size_dist,
            'num_groups': num_groups_dist,
            'inter_interval': inter_interval_dist
        }

        return distributions, new_hidden


# ==============================================================================
# <<< æ–°æ¶æ„ >>>: å®šä¹‰åŸºäº Encoder -> GRU -> Shared MLP çš„ Critic
#                       [ğŸ’¥ æ–°ç»“æ„: ç¼–ç å±‚ -> GRU -> MLP -> Head]
# ==============================================================================

class Critic_GRU(Module):
    """
    Critic ç½‘ç»œ (ä»·å€¼ç½‘ç»œ) - [æ··åˆæ¶æ„: Encoder -> GRU -> MLP]
    ç»“æ„ä¸º: ç¼–ç å±‚ -> GRU åºåˆ—å¤„ç† -> å…±äº«MLP -> è¾“å‡ºå¤´ã€‚
    """

    def __init__(self):
        super(Critic_GRU, self).__init__()
        self.input_dim = CRITIC_PARA.input_dim
        self.output_dim = CRITIC_PARA.output_dim
        self.rnn_hidden_size = RNN_HIDDEN_SIZE

        # # --- 1. [æ–°å¢] ç¼–ç å±‚ (Encoder) ---
        # self.encoder = Sequential(
        #     Linear(self.input_dim, self.rnn_hidden_size),
        #     LeakyReLU()
        # )

        # # --- [ä¿®æ”¹å]ï¼šåŒå±‚ + Tanh ---
        # enc_mid_dim = RNN_HIDDEN_SIZE * 2  # æˆ–è€… self.input_dim * 2
        # self.encoder = Sequential(
        #     Linear(self.input_dim, enc_mid_dim),
        #     LeakyReLU(),
        #     Linear(enc_mid_dim, self.rnn_hidden_size),
        #     # Tanh()  # <--- å…³é”®ä¿æŠ¤
        # )

        # --- 2. GRU å±‚ ---
        # self.gru = GRU(self.rnn_hidden_size, self.rnn_hidden_size, batch_first=True)

        # 2. GRU è¾“å…¥ç»´åº¦ç›´æ¥è®¾ä¸º input_dim
        self.gru = GRU(self.input_dim, self.rnn_hidden_size, batch_first=True)

        # --- 3. [ç§»åŠ¨] åç½® MLP (Post-GRU MLP) ---
        # GRU ä¹‹åæ˜¯å®Œæ•´çš„ MLP ç½‘ç»œè¿›è¡Œä»·å€¼è¯„ä¼°
        mlp_dims = CRITIC_PARA.model_layer_dim

        self.mlp = Sequential()
        input_dim = self.rnn_hidden_size
        for i, dim in enumerate(mlp_dims):
            self.mlp.add_module(f'mlp_fc_{i}', Linear(input_dim, dim))
            self.mlp.add_module(f'mlp_leakyrelu_{i}', LeakyReLU())
            input_dim = dim

        mlp_output_dim = mlp_dims[-1] if mlp_dims else self.rnn_hidden_size

        # --- 4. æœ€ç»ˆçš„è¾“å‡ºå¤´ (Head) ---
        self.fc_out = Linear(mlp_output_dim, self.output_dim)

        # --- åˆå§‹åŒ–æƒé‡ ---
        self.apply(init_weights)

        # --- 5. ä¼˜åŒ–å™¨è®¾ç½® ---
        gru_params = list(self.gru.parameters())
        other_params = (
                # list(self.encoder.parameters()) +
                list(self.mlp.parameters()) +
                list(self.fc_out.parameters())
        )

        param_groups = [
            {'params': gru_params, 'lr': CRITIC_PARA.gru_lr},
            {'params': other_params, 'lr': CRITIC_PARA.lr}
        ]
        self.optim = torch.optim.Adam(param_groups)
        self.critic_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
                                                      end_factor=AGENTPARA.mini_lr / CRITIC_PARA.lr,
                                                      total_iters=AGENTPARA.MAX_EXE_NUM)
        self.to(CRITIC_PARA.device)

    def forward(self, obs, hidden_state):
        obs_tensor = check(obs).to(**CRITIC_PARA.tpdv)
        is_sequence = obs_tensor.dim() == 3
        if not is_sequence:
            obs_tensor = obs_tensor.unsqueeze(1)

        # # 1. [æ–°] ç¼–ç å±‚
        # encoded_features = self.encoder(obs_tensor)

        # 2. GRU
        # gru_out, new_hidden = self.gru(encoded_features, hidden_state)
        gru_out, new_hidden = self.gru(obs_tensor, hidden_state)

        # 3. [æ–°] MLP
        mlp_features = self.mlp(gru_out)

        # å¤„ç†å•æ­¥è¾“å…¥çš„æƒ…å†µ
        if not is_sequence:
            mlp_features = mlp_features.squeeze(1)

        # 4. è¾“å‡ºå¤´
        value = self.fc_out(mlp_features)

        return value, new_hidden


# ==============================================================================
# Original MLP-based Actor and Critic (ä¿ç•™åŸå§‹ç‰ˆæœ¬ä»¥ä¾›é€‰æ‹©)
# ==============================================================================

class Actor(Module):
    # ... åŸç‰ˆ Actor ä»£ç ä¿æŒä¸å˜ ...
    """
       Actor ç½‘ç»œ (ç­–ç•¥ç½‘ç»œ) - åŸºäº MLPï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰çš„ç‰ˆæœ¬ã€‚
       è¯¥ç½‘ç»œè´Ÿè´£æ ¹æ®å½“å‰çŠ¶æ€å†³å®šè¦é‡‡å–çš„åŠ¨ä½œç­–ç•¥ã€‚
       å®ƒå…·æœ‰ä¸€ä¸ªå…±äº«çš„éª¨å¹²ç½‘ç»œï¼Œåæ¥ä¸¤ä¸ªç‹¬ç«‹çš„å¤´éƒ¨ï¼Œåˆ†åˆ«å¤„ç†è¿ç»­åŠ¨ä½œå’Œç¦»æ•£åŠ¨ä½œã€‚
        [ğŸ’¥ ä¿®æ”¹] è¿ç»­åŠ¨ä½œéƒ¨åˆ†ï¼šmu å¤´çŠ¶æ€ä¾èµ–ï¼Œlog_std ä¸ºå…¨å±€å¯å­¦ä¹ å‚æ•°ã€‚
       """

    def __init__(self):
        super(Actor, self).__init__()
        self.input_dim = ACTOR_PARA.input_dim
        # <<< æ›´æ”¹ >>> è¾“å‡ºç»´åº¦ç°åœ¨æ˜¯ (è¿ç»­*2) + æ–°çš„logitsæ€»æ•°
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†éœ€è¦ä¸€ä¸ªæ€»çš„ output_dim
        # self.output_dim = (CONTINUOUS_DIM * 2) + TOTAL_DISCRETE_LOGITS
        self.log_std_min = -20.0 # é™åˆ¶å¯¹æ•°æ ‡å‡†å·®çš„æœ€å°å€¼ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        self.log_std_max = 2.0 # é™åˆ¶å¯¹æ•°æ ‡å‡†å·®çš„æœ€å¤§å€¼

        # å®šä¹‰å…±äº«éª¨å¹²ç½‘ç»œ
        # è´Ÿè´£ä»åŸå§‹çŠ¶æ€ä¸­æå–é«˜çº§ç‰¹å¾
        shared_layers_dims = [self.input_dim] + ACTOR_PARA.model_layer_dim
        self.shared_network = Sequential()
        for i in range(len(shared_layers_dims) - 1):
            # æ·»åŠ çº¿æ€§ï¼ˆå…¨è¿æ¥ï¼‰å±‚
            self.shared_network.add_module(f'fc_{i}', Linear(shared_layers_dims[i], shared_layers_dims[i + 1]))
            # --- åœ¨æ­¤å¤„æ·»åŠ  LayerNorm ---
            # LayerNorm çš„è¾“å…¥ç»´åº¦æ˜¯å‰ä¸€ä¸ªçº¿æ€§å±‚çš„è¾“å‡ºç»´åº¦
            # LayerNorm å¯¹æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒ
            # self.shared_network.add_module(f'LayerNorm_{i}', LayerNorm(shared_layers_dims[i + 1]))
            # æ·»åŠ  LeakyReLU æ¿€æ´»å‡½æ•°ï¼Œä»¥é¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
            self.shared_network.add_module(f'LeakyReLU_{i}', LeakyReLU())

        # éª¨å¹²ç½‘ç»œçš„è¾“å‡ºç»´åº¦ï¼Œå°†ä½œä¸ºå„ä¸ªå¤´éƒ¨çš„è¾“å…¥
        shared_output_dim = ACTOR_PARA.model_layer_dim[-1]
        # --- ç‹¬ç«‹å¤´éƒ¨ç½‘ç»œ ---
        # # 1. è¿ç»­åŠ¨ä½œå¤´éƒ¨ï¼šè¾“å‡ºé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ (mu) å’Œå¯¹æ•°æ ‡å‡†å·® (log_std)ï¼Œæ¯ä¸ªè¿ç»­åŠ¨ä½œç»´åº¦éƒ½éœ€è¦è¿™ä¸¤ä¸ªå‚æ•°
        # self.continuous_head = Linear(shared_output_dim, CONTINUOUS_DIM * 2)
        # --- ğŸ’¥ [ä¿®æ”¹] ç‹¬ç«‹å¤´éƒ¨ç½‘ç»œ ---
        # mu å¤´éƒ¨
        self.mu_head = Linear(shared_output_dim, CONTINUOUS_DIM)
        # log_std ä½œä¸ºç‹¬ç«‹çš„ã€ä¸çŠ¶æ€æ— å…³çš„å¯å­¦ä¹ å‚æ•°
        self.log_std_param = torch.nn.Parameter(torch.zeros(1, CONTINUOUS_DIM) * -0.5)

        # 2. ç¦»æ•£åŠ¨ä½œå¤´éƒ¨ï¼šè¾“å‡ºæ‰€æœ‰ç¦»æ•£å†³ç­–æ‰€éœ€çš„ logitsï¼ˆæœªç» Softmax çš„åŸå§‹åˆ†æ•°ï¼‰
        self.discrete_head = Linear(shared_output_dim, TOTAL_DISCRETE_LOGITS)

        # self.init_model() # (è¢«æ³¨é‡Šæ‰ï¼Œå› ä¸ºç½‘ç»œç»“æ„åœ¨ init ä¸­ç›´æ¥å®šä¹‰)
        # --- ä¼˜åŒ–å™¨å’Œè®¾å¤‡è®¾ç½® ---
        self.optim = torch.optim.Adam(self.parameters(), ACTOR_PARA.lr)
        self.actor_scheduler = lr_scheduler.LinearLR(
            self.optim,
            start_factor=1.0,# åˆå§‹å­¦ä¹ ç‡å› å­
            end_factor=AGENTPARA.mini_lr / ACTOR_PARA.lr,# æœ€ç»ˆå­¦ä¹ ç‡å› å­
            total_iters=AGENTPARA.MAX_EXE_NUM # è¾¾åˆ°æœ€ç»ˆå­¦ä¹ ç‡æ‰€éœ€çš„æ€»è¿­ä»£æ¬¡æ•°
        )
        self.to(ACTOR_PARA.device) # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ (CPU æˆ– GPU)

    def forward(self, obs):
        """
        å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œä¸ºæ¯ä¸ªåŠ¨ä½œç»´åº¦åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚
        """
        # ç¡®ä¿è¾“å…¥æ˜¯ PyTorch å¼ é‡å¹¶ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        obs_tensor = check(obs).to(**ACTOR_PARA.tpdv)
        # å¦‚æœè¾“å…¥æ˜¯ä¸€ç»´çš„ï¼ˆå•ä¸ªçŠ¶æ€ï¼‰ï¼Œå¢åŠ ä¸€ä¸ªæ‰¹æ¬¡ç»´åº¦
        if obs_tensor.dim() == 1:
            obs_tensor = obs_tensor.unsqueeze(0)

        # 1. é€šè¿‡å…±äº«éª¨å¹²ç½‘ç»œæå–é€šç”¨ç‰¹å¾
        shared_features = self.shared_network(obs_tensor)

        # 2. å°†å…±äº«ç‰¹å¾åˆ†åˆ«é€å…¥ä¸åŒçš„å¤´éƒ¨ç½‘ç»œ
        # cont_params = self.continuous_head(shared_features) # è·å–è¿ç»­åŠ¨ä½œçš„å‚æ•°
        # --- ğŸ’¥ [ä¿®æ”¹] ä»ä¸åŒå¤´è·å–å‚æ•° ---
        mu = self.mu_head(shared_features)
        all_disc_logits = self.discrete_head(shared_features) # è·å–æ‰€æœ‰ç¦»æ•£åŠ¨ä½œçš„ logits

        # ... åç»­é€»è¾‘ä¸åŸç‰ˆå®Œå…¨ç›¸åŒ ...
        # æ ¹æ® DISCRETE_DIMS çš„å®šä¹‰ï¼Œå°†æ€»çš„ logits åˆ‡åˆ†æˆå¯¹åº”æ¯ä¸ªç¦»æ•£åŠ¨ä½œçš„éƒ¨åˆ†
        split_sizes = list(DISCRETE_DIMS.values())
        logits_parts = torch.split(all_disc_logits, split_sizes, dim=1)
        trigger_logits, salvo_size_logits, intra_interval_logits, num_groups_logits, inter_interval_logits = logits_parts
        # è·å–çŠ¶æ€ä¸­å…³äºå¹²æ‰°å¼¹æ•°é‡çš„ä¿¡æ¯ï¼ˆç´¢å¼•ä¸º7ï¼‰
        has_flares_info = obs_tensor[:, 7]
        # åˆ›å»ºä¸€ä¸ªæ©ç ï¼Œå½“å¹²æ‰°å¼¹æ•°é‡ä¸º0æ—¶ä¸º True
        mask = (has_flares_info == 0)
        trigger_logits_masked = trigger_logits.clone()
        # å¦‚æœå­˜åœ¨å¹²æ‰°å¼¹æ•°é‡ä¸º0çš„æƒ…å†µï¼Œå°†å¯¹åº”çš„ trigger_logits è®¾ç½®ä¸ºè´Ÿæ— ç©·å¤§
        # è¿™æ ·åœ¨åº”ç”¨ sigmoid/softmax åï¼Œè§¦å‘æ¦‚ç‡ä¼šè¶‹è¿‘äº0ï¼Œå®ç°äº†åŠ¨ä½œå±è”½
        if torch.any(mask):
            trigger_logits_masked[mask] = torch.finfo(torch.float32).min
        # # ä»è¿ç»­åŠ¨ä½œå‚æ•°ä¸­åˆ†ç¦»å‡ºå‡å€¼å’Œå¯¹æ•°æ ‡å‡†å·®
        # mu, log_std = cont_params.chunk(2, dim=-1)
        # è£å‰ªå¯¹æ•°æ ‡å‡†å·®ä»¥ä¿è¯æ•°å€¼ç¨³å®šæ€§
        # log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)
        # # è®¡ç®—æ ‡å‡†å·®
        # std = torch.exp(log_std)

        # --- ğŸ’¥ [ä¿®æ”¹] åˆ›å»ºè¿ç»­åŠ¨ä½œåˆ†å¸ƒ ---
        log_std = torch.clamp(self.log_std_param, self.log_std_min, self.log_std_max)
        std = torch.exp(log_std).expand_as(mu)
        # åˆ›å»ºè¿ç»­åŠ¨ä½œçš„æ­£æ€åˆ†å¸ƒ
        continuous_base_dist = Normal(mu, std)
        # åˆ›å»ºç¦»æ•£åŠ¨ä½œçš„åˆ†å¸ƒ
        trigger_dist = Bernoulli(logits=trigger_logits_masked.squeeze(-1)) # ä¼¯åŠªåˆ©åˆ†å¸ƒ
        salvo_size_dist = Categorical(logits=salvo_size_logits) # åˆ†ç±»åˆ†å¸ƒ
        intra_interval_dist = Categorical(logits=intra_interval_logits)
        num_groups_dist = Categorical(logits=num_groups_logits)
        inter_interval_dist = Categorical(logits=inter_interval_logits)
        # å°†æ‰€æœ‰åˆ†å¸ƒæ‰“åŒ…æˆä¸€ä¸ªå­—å…¸è¿”å›
        distributions = {
            'continuous': continuous_base_dist,
            'trigger': trigger_dist,
            'salvo_size': salvo_size_dist,
            'intra_interval': intra_interval_dist,
            'num_groups': num_groups_dist,
            'inter_interval': inter_interval_dist
        }
        return distributions


class Critic(Module):
    # ... åŸç‰ˆ Critic ä»£ç ä¿æŒä¸å˜ ...
    """
       Critic ç½‘ç»œ (ä»·å€¼ç½‘ç»œ)ï¼Œè¯„ä¼°çŠ¶æ€çš„ä»·å€¼ V(s)ã€‚
       è¿™æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ MLP æ¨¡å‹ï¼Œè´Ÿè´£é¢„æµ‹è¾“å…¥çŠ¶æ€çš„æœŸæœ›å›æŠ¥ã€‚
       """

    def __init__(self):
        super(Critic, self).__init__()
        self.input_dim = CRITIC_PARA.input_dim
        self.output_dim = CRITIC_PARA.output_dim
        self.init_model()
        self.optim = torch.optim.Adam(self.parameters(), CRITIC_PARA.lr)
        self.critic_scheduler = lr_scheduler.LinearLR(
            self.optim,
            start_factor=1.0,
            end_factor=AGENTPARA.mini_lr / CRITIC_PARA.lr,
            total_iters=AGENTPARA.MAX_EXE_NUM
        )
        self.to(CRITIC_PARA.device)

    def init_model(self):
        """åˆå§‹åŒ– Critic çš„ç½‘ç»œç»“æ„ã€‚"""
        self.network = Sequential()
        layers_dims = [self.input_dim] + CRITIC_PARA.model_layer_dim
        for i in range(len(layers_dims) - 1):
            self.network.add_module(f'fc_{i}', Linear(layers_dims[i], layers_dims[i + 1]))
            self.network.add_module(f'LayerNorm_{i}', LayerNorm(layers_dims[i + 1]))
            self.network.add_module(f'LeakyReLU_{i}', LeakyReLU())
        # è¾“å‡ºå±‚ï¼Œè¾“å‡ºä¸€ä¸ªæ ‡é‡å€¼ï¼Œå³çŠ¶æ€ä»·å€¼ V(s)
        self.network.add_module('fc_out', Linear(layers_dims[-1], self.output_dim))

    def forward(self, obs):
        """å‰å‘ä¼ æ’­ï¼Œè®¡ç®—çŠ¶æ€ä»·å€¼ã€‚"""
        obs = check(obs).to(**CRITIC_PARA.tpdv)
        value = self.network(obs)
        return value

# ==============================================================================
# <<< GRU/RNN ä¿®æ”¹ >>>: å®šä¹‰æ–°çš„åŸºäº GRU çš„ Actor å’Œ Critic
#                       [ğŸ’¥ æ–°ç»“æ„: GRU -> MLP -> Heads]
# ==============================================================================

def init_weights(m, gain=1.0):
    """
    ä¸€ä¸ªé€šç”¨çš„æƒé‡åˆå§‹åŒ–å‡½æ•°ã€‚
    :param m: PyTorch module
    :param gain: æ­£äº¤åˆå§‹åŒ–çš„å¢ç›Šå› å­
    """
    # if isinstance(m, Linear):
    #     # å¯¹çº¿æ€§å±‚ä½¿ç”¨ Kaiming Normal åˆå§‹åŒ–ï¼Œé€‚ç”¨äº LeakyReLU
    #     torch.nn.init.kaiming_normal_(m.weight, a=0.01, mode='fan_in', nonlinearity='leaky_relu')
    #     if m.bias is not None:
    #         torch.nn.init.constant_(m.bias, 0)
    if isinstance(m, GRU):
        # å¯¹ GRU çš„æƒé‡ä½¿ç”¨æ­£äº¤åˆå§‹åŒ–ï¼Œè¿™æ˜¯ RNN çš„æœ€ä½³å®è·µ
        for name, param in m.named_parameters():
            if 'weight_ih' in name:
                torch.nn.init.orthogonal_(param.data, gain=gain)
            elif 'weight_hh' in name:
                torch.nn.init.orthogonal_(param.data, gain=gain)
            elif 'bias' in name:
                param.data.fill_(0)
# # ==============================================================================
# # <<< GRU/RNN ä¿®æ”¹ >>>: å®šä¹‰æ–°çš„åŸºäº GRU çš„ Actor å’Œ Critic
# #                       [ğŸ’¥ æ–°ç»“æ„: GRU -> MLP -> Heads]
# # ==============================================================================
#
# class Actor_GRU(Module):
#     """
#         Actor ç½‘ç»œ (ç­–ç•¥ç½‘ç»œ) - åŸºäº GRU çš„ç‰ˆæœ¬ã€‚
#         ç»“æ„ä¸º: MLP ç‰¹å¾æå– -> GRU åºåˆ—å¤„ç† -> ç‹¬ç«‹åŠ¨ä½œå¤´ã€‚
#         è¿™ç§ç»“æ„èƒ½å¤Ÿæ•æ‰çŠ¶æ€åºåˆ—ä¸­çš„æ—¶é—´ä¾èµ–å…³ç³»ã€‚
#         [ğŸ’¥ ä¿®æ”¹] è¿ç»­åŠ¨ä½œéƒ¨åˆ†ï¼šmu å¤´çŠ¶æ€ä¾èµ–ï¼Œlog_std ä¸ºå…¨å±€å¯å­¦ä¹ å‚æ•°ã€‚
#         """
#     """
#     Actor ç½‘ç»œ (ç­–ç•¥ç½‘ç»œ) - [æœ€ç»ˆæ··åˆæ¶æ„: GRU -> Hybrid MLP]
#     ç»“æ„ä¸º: GRU åºåˆ—å¤„ç† -> å…±äº«MLPåŸºåº§ -> ä¸“ç”¨MLPå¡”æ¥¼ -> ç‹¬ç«‹åŠ¨ä½œå¤´ã€‚
#     """
#     def __init__(self):
#         super(Actor_GRU, self).__init__()
#         self.input_dim = ACTOR_PARA.input_dim
#         self.log_std_min = -20.0
#         self.log_std_max = 2.0
#         self.rnn_hidden_size =  RNN_HIDDEN_SIZE #RNN_HIDDEN_SIZE  self.input_dim
#
#         # 1. GRU å±‚ä½œä¸ºç¬¬ä¸€å±‚ï¼Œç›´æ¥å¤„ç†åŸå§‹çŠ¶æ€è¾“å…¥
#         self.gru = GRU(self.input_dim, self.rnn_hidden_size, batch_first=True)
#
#         # --- ç§»æ¤è¿‡æ¥çš„æ··åˆæ¶æ„å®šä¹‰ ---
#         # è¿™ä¸ªæ··åˆæ¶æ„ç°åœ¨å¤„ç†çš„æ˜¯ GRU çš„è¾“å‡ºï¼Œè€Œä¸æ˜¯åŸå§‹è¾“å…¥
#         # 2. å®šä¹‰ MLP å„éƒ¨åˆ†çš„ç»´åº¦
#         #    å‡è®¾ model_layer_dim = [256, 256ï¼Œ256], split_point = 1
#         split_point = 2  # åœ¨ MLP çš„ç¬¬2å±‚åæ‹†åˆ†
#         base_dims = ACTOR_PARA.model_layer_dim[:split_point]  # ä¾‹å¦‚: [256,256]
#         continuous_tower_dims = ACTOR_PARA.model_layer_dim[split_point:]  # ä¾‹å¦‚: [256]
#         discrete_tower_dims = continuous_tower_dims
#         # è®©ç¦»æ•£å¡”æ¥¼çš„ç»´åº¦æ˜¯è¿ç»­å¡”æ¥¼çš„ä¸€åŠ
#         # discrete_tower_dims = [dim // 2 for dim in continuous_tower_dims]  # ä¾‹å¦‚: [128]
#
#         # 3. æ„å»ºå…±äº«MLPåŸºåº§ (Shared Base MLP)
#         self.shared_base_mlp = Sequential()
#         # MLPçš„è¾“å…¥ç»´åº¦æ˜¯ GRU çš„éšè—å±‚å¤§å°
#         base_input_dim = self.rnn_hidden_size
#         for i, dim in enumerate(base_dims):
#             self.shared_base_mlp.add_module(f'base_fc_{i}', Linear(base_input_dim, dim))
#             self.shared_base_mlp.add_module(f'base_leakyrelu_{i}', LeakyReLU())
#             base_input_dim = dim
#         base_output_dim = base_dims[-1] if base_dims else self.rnn_hidden_size
#
#         # 4. æ„å»ºè¿ç»­åŠ¨ä½œå¡”æ¥¼ (Continuous Tower)
#         self.continuous_tower = Sequential()
#         tower_input_dim = base_output_dim
#         for i, dim in enumerate(continuous_tower_dims):
#             self.continuous_tower.add_module(f'cont_tower_fc_{i}', Linear(tower_input_dim, dim))
#             self.continuous_tower.add_module(f'cont_tower_leakyrelu_{i}', LeakyReLU())
#             tower_input_dim = dim
#         continuous_tower_output_dim = continuous_tower_dims[-1] if continuous_tower_dims else base_output_dim
#
#         # 5. æ„å»ºç¦»æ•£åŠ¨ä½œå¡”æ¥¼ (Discrete Tower)
#         self.discrete_tower = Sequential()
#         tower_input_dim = base_output_dim
#         for i, dim in enumerate(discrete_tower_dims):
#             self.discrete_tower.add_module(f'disc_tower_fc_{i}', Linear(tower_input_dim, dim))
#             self.discrete_tower.add_module(f'disc_tower_leakyrelu_{i}', LeakyReLU())
#             tower_input_dim = dim
#         discrete_tower_output_dim = discrete_tower_dims[-1] if discrete_tower_dims else base_output_dim
#
#         # 6. å®šä¹‰æœ€ç»ˆçš„è¾“å‡ºå¤´ (Heads)
#         self.mu_head = Linear(continuous_tower_output_dim, CONTINUOUS_DIM)
#         self.discrete_head = Linear(discrete_tower_output_dim, TOTAL_DISCRETE_LOGITS)
#         self.log_std_param = torch.nn.Parameter(torch.full((1, CONTINUOUS_DIM), 0.0))
#
#         # <<< MODIFICATION START: ç²¾ç»†åŒ–ä¼˜åŒ–å™¨è®¾ç½® >>>
#         # 1. å°†å‚æ•°åˆ†ä¸º GRU å‚æ•° å’Œ å…¶ä»–å‚æ•°
#         gru_params = []
#         other_params = []
#         for name, param in self.named_parameters():
#             if not param.requires_grad:
#                 continue
#             # æ ¹æ®å‚æ•°åä¸­æ˜¯å¦åŒ…å« 'gru' æ¥è¿›è¡Œåˆ†ç»„
#             if 'gru' in name.lower():
#                 gru_params.append(param)
#             else:
#                 other_params.append(param)
#
#         # 2. åˆ›å»ºå‚æ•°ç»„ (parameter groups) åˆ—è¡¨
#         param_groups = [
#             {
#                 'params': gru_params,
#                 'lr': ACTOR_PARA.gru_lr  # ä¸º GRU å‚æ•°è®¾ç½®ä¸“å±å­¦ä¹ ç‡
#             },
#             {
#                 'params': other_params  # å…¶ä»–æ‰€æœ‰å‚æ•° (MLP, Heads)
#                 # ä¸æŒ‡å®š lrï¼Œå°†ä½¿ç”¨ä¸‹é¢ Adam æ„é€ å‡½æ•°ä¸­çš„é»˜è®¤ lr
#             }
#         ]
#
#         # 3. ä½¿ç”¨å‚æ•°ç»„åˆå§‹åŒ–ä¼˜åŒ–å™¨
#         # é»˜è®¤ lr å°†ç”¨äº 'other_params' ç»„
#         self.optim = torch.optim.Adam(param_groups, lr=ACTOR_PARA.lr)
#
#         print("--- Actor_GRU Optimizer Initialized with Parameter Groups ---")
#         print(f"  - GRU Params LR: {ACTOR_PARA.gru_lr}")
#         print(f"  - Other (MLP) Params LR: {ACTOR_PARA.lr}")
#         # <<< MODIFICATION END >>>
#
#         # ä¼˜åŒ–å™¨ç­‰è®¾ç½®
#         # self.optim = torch.optim.Adam(self.parameters(), ACTOR_PARA.lr)
#         self.actor_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
#                                                      end_factor=AGENTPARA.mini_lr / ACTOR_PARA.lr,
#                                                      total_iters=AGENTPARA.MAX_EXE_NUM)
#         self.to(ACTOR_PARA.device)
#
#     def forward(self, obs, hidden_state):
#         """
#         GRU Actor çš„å‰å‘ä¼ æ’­ã€‚
#         è¿™ä¸ªæ–¹æ³•è¢«è®¾è®¡ä¸ºå¯ä»¥åŒæ—¶å¤„ç†å•ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ï¼ˆç”¨äºä¸ç¯å¢ƒäº¤äº’ï¼‰å’Œåºåˆ—è¾“å…¥ï¼ˆç”¨äºè®­ç»ƒï¼‰ã€‚
#         Args:
#             obs (Tensor): è§‚æµ‹å€¼ã€‚å½¢çŠ¶å¯ä»¥æ˜¯ (batch, features) ç”¨äºå•æ­¥ï¼Œæˆ– (batch, seq_len, features) ç”¨äºåºåˆ—ã€‚
#             hidden_state (Tensor): GRU çš„éšè—çŠ¶æ€ã€‚å½¢çŠ¶æ˜¯ (num_layers=1, batch, rnn_hidden_size)ã€‚
#         Returns:
#             tuple: (åŒ…å«æ‰€æœ‰åŠ¨ä½œåˆ†å¸ƒçš„å­—å…¸, æ–°çš„éšè—çŠ¶æ€)
#         """
#         obs_tensor = check(obs).to(**ACTOR_PARA.tpdv)
#         # æ£€æŸ¥è¾“å…¥æ˜¯å•ä¸ªæ—¶é—´æ­¥è¿˜æ˜¯åºåˆ—ï¼Œé€šè¿‡åˆ¤æ–­å¼ é‡çš„ç»´åº¦
#         is_sequence = obs_tensor.dim() == 3
#
#         # ç»Ÿä¸€å¤„ç†è¾“å…¥å½¢çŠ¶ï¼Œä½¿å…¶ç¬¦åˆ GRU çš„è¾“å…¥è¦æ±‚ (batch, seq_len, features)
#         if not is_sequence:
#             # å¦‚æœæ˜¯å•æ­¥ (batch_size, features)ï¼Œå¢åŠ ä¸€ä¸ª seq_len=1 çš„ç»´åº¦
#             obs_tensor = obs_tensor.unsqueeze(1)  # -> (batch_size, 1, features)
#
#         # 1. åŸå§‹çŠ¶æ€åºåˆ—é¦–å…ˆé€šè¿‡ GRU
#         gru_out, new_hidden = self.gru(obs_tensor, hidden_state)
#
#         # --- æ–°çš„æ··åˆ MLP æ•°æ®æµ ---
#         # 2. GRU çš„è¾“å‡ºæµç»å…±äº« MLP åŸºåº§
#         base_features = self.shared_base_mlp(gru_out)
#
#         # 3. å…±äº«ç‰¹å¾è¢«åˆ†åˆ«é€å…¥ä¸¤ä¸ªä¸“ç”¨å¡”æ¥¼
#         continuous_features = self.continuous_tower(base_features)
#         discrete_features = self.discrete_tower(base_features)
#
#         # 4. å¦‚æœæ˜¯å•æ­¥è¾“å…¥ï¼Œå‹ç¼©ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…å¤´éƒ¨
#         if not is_sequence:
#             continuous_features = continuous_features.squeeze(1)
#             discrete_features = discrete_features.squeeze(1)
#
#         # 5. æ¯ä¸ªå¤´éƒ¨æ¥æ”¶æ¥è‡ªå…¶ä¸“å±å¡”æ¥¼çš„ç‰¹å¾
#         mu = self.mu_head(continuous_features)
#         all_disc_logits = self.discrete_head(discrete_features)
#
#         # åç»­çš„åˆ†å¸ƒåˆ›å»ºé€»è¾‘ä¸åŸç‰ˆ Actor å®Œå…¨ç›¸åŒ
#         split_sizes = list(DISCRETE_DIMS.values())
#         logits_parts = torch.split(all_disc_logits, split_sizes, dim=-1)
#         # trigger_logits, salvo_size_logits, intra_interval_logits, num_groups_logits, inter_interval_logits = logits_parts
#         trigger_logits, salvo_size_logits, num_groups_logits, inter_interval_logits = logits_parts
#         # å…³é”®ï¼šåŠ¨ä½œæ©ç ä¾èµ–äºåŸå§‹è¾“å…¥ obs_tensorï¼Œè€Œä¸æ˜¯ GRU çš„è¾“å‡º
#         # åŠ¨ä½œæ©ç é€»è¾‘ (éœ€è¦æ³¨æ„åœ¨åºåˆ—æƒ…å†µä¸‹æ­£ç¡®ç´¢å¼•)
#         # obs_tensor æ­¤æ—¶å¯èƒ½æ˜¯ (batch, seq_len, features) æˆ– (batch, features)
#         # ä½¿ç”¨ ... (Ellipsis) å¯ä»¥ä¼˜é›…åœ°å¤„ç†è¿™ä¸¤ç§æƒ…å†µï¼Œå®ƒä»£è¡¨ä»»æ„æ•°é‡çš„å‰å¯¼ç»´åº¦ã€‚
#         has_flares_info = obs_tensor[..., 7]  # ä½¿ç”¨ ... æ¥å¤„ç†å•æ­¥å’Œåºåˆ—ä¸¤ç§æƒ…å†µ
#         mask = (has_flares_info == 0)
#         trigger_logits_masked = trigger_logits.clone()
#         if torch.any(mask):
#             # unsqueeze a dim to match the mask shape with trigger_logits_masked if they are different
#             if mask.dim() < trigger_logits_masked.dim():
#                 mask = mask.unsqueeze(-1)
#             trigger_logits_masked[mask] = torch.finfo(torch.float32).min
#
#         # ===============================================================
#         # 5ï¸âƒ£ è§¦å‘å™¨å±‚æ¬¡æ§åˆ¶ï¼šå½“â€œä¸æŠ•æ”¾â€æ—¶ï¼Œå±è”½å…¶ä»–ç¦»æ•£åŠ¨ä½œ logits
#         # ===============================================================
#         # å…ˆå¾—åˆ°è§¦å‘å™¨åˆ†å¸ƒ
#         trigger_probs = torch.sigmoid(trigger_logits_masked)  # shape: [B,1]
#
#         # å¦‚æœ trigger_probs < 0.5ï¼Œè¯´æ˜æ¨¡å‹å€¾å‘äºâ€œä¸æŠ•æ”¾â€
#         # æˆ‘ä»¬ç”¨è¿™ä¸ªæ¡ä»¶ç”Ÿæˆä¸€ä¸ª maskï¼ˆTrue=ä¸æŠ•æ”¾ï¼‰
#         no_trigger_mask = (trigger_probs < 0.5).squeeze(-1)  # shape: [B]
#
#         # åˆ›å»º logits çš„å‰¯æœ¬ï¼Œé¿å…åŸåœ°æ“ä½œæ±¡æŸ“æ¢¯åº¦
#         salvo_size_logits_masked = salvo_size_logits.clone()
#         # intra_interval_logits_masked = intra_interval_logits.clone()
#         num_groups_logits_masked = num_groups_logits.clone()
#         inter_interval_logits_masked = inter_interval_logits.clone()
#         # ===============================================================
#         # å½“ trigger ä¸æŠ•æ”¾æ—¶ï¼Œå°†å…¶ä»–ç¦»æ•£åŠ¨ä½œ logits å¼ºåˆ¶ä¸º index=0 (one-hot å½¢å¼)
#         # ===============================================================
#         if torch.any(no_trigger_mask):
#             INF = 1e6
#             NEG_INF = -1e6
#             for logits_tensor in [
#                 salvo_size_logits_masked,
#                 # intra_interval_logits_masked,
#                 num_groups_logits_masked,
#                 inter_interval_logits_masked,
#             ]:
#                 logits_sub = logits_tensor[no_trigger_mask]
#                 if logits_sub.numel() > 0:
#                     logits_sub[:] = NEG_INF  # å…¨éƒ¨ç½®ä¸ºæå°å€¼
#                     logits_sub[:, 0] = INF  # ä»… index=0 ç½®ä¸ºæå¤§å€¼
#                     logits_tensor[no_trigger_mask] = logits_sub
#
#
#         # mu, log_std = cont_params.chunk(2, dim=-1)
#         # log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)
#         # std = torch.exp(log_std)
#         # --- ğŸ’¥ [ä¿®æ”¹] 5. åˆ›å»ºè¿ç»­åŠ¨ä½œåˆ†å¸ƒ ---
#         # ä½¿ç”¨å…¨å±€å¯å­¦ä¹ çš„ log_std å‚æ•°
#         log_std = torch.clamp(self.log_std_param, self.log_std_min, self.log_std_max)
#         # ä½¿ç”¨ .expand_as(mu) æ¥åŒ¹é…æ‰¹æ¬¡å’Œåºåˆ—ç»´åº¦
#         std = torch.exp(log_std).expand_as(mu)
#         continuous_base_dist = Normal(mu, std)
#
#         # Bernoulli çš„ logits éœ€è¦ç§»é™¤æœ€åä¸€ä¸ªç»´åº¦ï¼ˆå¦‚æœå®ƒå­˜åœ¨ä¸”ä¸º1ï¼‰
#         trigger_dist = Bernoulli(logits=trigger_logits_masked.squeeze(-1))
#         salvo_size_dist = Categorical(logits=salvo_size_logits_masked)
#         # intra_interval_dist = Categorical(logits=intra_interval_logits_masked)
#         num_groups_dist = Categorical(logits=num_groups_logits_masked)
#         inter_interval_dist = Categorical(logits=inter_interval_logits_masked)
#
#         distributions = {
#             'continuous': continuous_base_dist,
#             'trigger': trigger_dist,
#             'salvo_size': salvo_size_dist,
#             # 'intra_interval': intra_interval_dist,
#             'num_groups': num_groups_dist,
#             'inter_interval': inter_interval_dist
#         }
#
#         return distributions, new_hidden
#
#
# class Critic_GRU(Module):
#     """
#     Critic ç½‘ç»œ (ä»·å€¼ç½‘ç»œ) - åŸºäº GRU çš„ç‰ˆæœ¬ã€‚
#     ç»“æ„ä¸º: MLP ç‰¹å¾æå– -> GRU åºåˆ—å¤„ç† -> è¾“å‡ºå¤´ã€‚
#     ç”¨äºè¯„ä¼°çŠ¶æ€åºåˆ—çš„ä»·å€¼ã€‚
#     """
#     """
#        Critic ç½‘ç»œ (ä»·å€¼ç½‘ç»œ) - [æ–°ç»“æ„: GRU -> MLP]
#        ç»“æ„ä¸º: GRU åºåˆ—å¤„ç† -> MLP ç‰¹å¾æå– -> è¾“å‡ºå¤´ã€‚
#        """
#     def __init__(self):
#         super(Critic_GRU, self).__init__()
#         self.input_dim = CRITIC_PARA.input_dim
#         self.output_dim = CRITIC_PARA.output_dim
#         self.rnn_hidden_size = RNN_HIDDEN_SIZE #RNN_HIDDEN_SIZE  self.input_dim
#
#         # # 1. MLP éª¨å¹²ç½‘ç»œ (ä¸åŸç‰ˆ Critic ç±»ä¼¼)
#         # self.network_base = Sequential()
#         # layers_dims = [self.input_dim] + CRITIC_PARA.model_layer_dim
#         # for i in range(len(layers_dims) - 1):
#         #     self.network_base.add_module(f'fc_{i}', Linear(layers_dims[i], layers_dims[i + 1]))
#         #     self.network_base.add_module(f'LayerNorm_{i}', LayerNorm(layers_dims[i + 1]))
#         #     self.network_base.add_module(f'LeakyReLU_{i}', LeakyReLU())
#         #
#         # base_output_dim = CRITIC_PARA.model_layer_dim[-1]
#         #
#         # # 2. GRU å±‚
#         # self.gru = GRU(base_output_dim, self.rnn_hidden_size, batch_first=True)
#         #
#         # # 3. è¾“å‡ºå¤´ï¼Œå°† GRU çš„è¾“å‡ºæ˜ å°„åˆ°æœ€ç»ˆçš„ä»·å€¼ V(s)
#         # self.fc_out = Linear(self.rnn_hidden_size, self.output_dim)
#
#         # 1. GRU å±‚ä½œä¸ºç¬¬ä¸€å±‚
#         self.gru = GRU(self.input_dim, self.rnn_hidden_size, batch_first=True)
#
#         # # ğŸ’¥ åœ¨ GRU å’Œ MLP ä¹‹é—´æ–°å¢ä¸€ä¸ª LayerNorm
#         # self.mlp_input_layernorm = LayerNorm(self.rnn_hidden_size)
#
#         # 2. MLP éª¨å¹²ç½‘ç»œï¼Œæ¥æ”¶ GRU çš„è¾“å‡º
#         # MLPçš„è¾“å…¥ç»´åº¦æ˜¯ GRU çš„éšè—å±‚å¤§å°
#         layers_dims = [self.rnn_hidden_size] + CRITIC_PARA.model_layer_dim
#         self.network_base = Sequential()
#         for i in range(len(layers_dims) - 1):
#             self.network_base.add_module(f'fc_{i}', Linear(layers_dims[i], layers_dims[i + 1]))
#             # self.network_base.add_module(f'LayerNorm_{i}', LayerNorm(layers_dims[i + 1]))
#             self.network_base.add_module(f'LeakyReLU_{i}', LeakyReLU())
#
#         # MLP çš„è¾“å‡ºç»´åº¦
#         base_output_dim = CRITIC_PARA.model_layer_dim[-1]
#
#         # 3. è¾“å‡ºå¤´ï¼Œæ¥æ”¶ MLP çš„è¾“å‡º
#         self.fc_out = Linear(base_output_dim, self.output_dim)
#
#         # # --- [æ–°å¢] åº”ç”¨åˆå§‹åŒ– ---
#         # self.apply(init_weights)  # å¯¹æ‰€æœ‰å­æ¨¡å—åº”ç”¨é€šç”¨åˆå§‹åŒ–
#         #
#         # # --- [æ–°å¢] å¯¹è¾“å‡ºå±‚è¿›è¡Œç‰¹æ®Šåˆå§‹åŒ– ---
#         # # è¿™æ ·åšæ˜¯ä¸ºäº†åœ¨è®­ç»ƒå¼€å§‹æ—¶æœ‰æ›´ç¨³å®šçš„ä»·å€¼ä¼°è®¡
#         # init_range = 3e-3
#         # self.fc_out.weight.data.uniform_(-init_range, init_range)
#         # self.fc_out.bias.data.fill_(0)
#         # # --- åˆå§‹åŒ–ç»“æŸ ---
#
#         # <<< MODIFICATION START: ç²¾ç»†åŒ–ä¼˜åŒ–å™¨è®¾ç½® >>>
#         # 1. å°†å‚æ•°åˆ†ä¸º GRU å‚æ•° å’Œ å…¶ä»–å‚æ•°
#         gru_params = []
#         other_params = []
#         for name, param in self.named_parameters():
#             if not param.requires_grad:
#                 continue
#             if 'gru' in name.lower():
#                 gru_params.append(param)
#             else:
#                 other_params.append(param)
#
#         # 2. åˆ›å»ºå‚æ•°ç»„ (parameter groups) åˆ—è¡¨
#         param_groups = [
#             {
#                 'params': gru_params,
#                 'lr': CRITIC_PARA.gru_lr  # ä¸º GRU å‚æ•°è®¾ç½®ä¸“å±å­¦ä¹ ç‡
#             },
#             {
#                 'params': other_params  # å…¶ä»–æ‰€æœ‰å‚æ•° (MLP, Head)
#             }
#         ]
#
#         # 3. ä½¿ç”¨å‚æ•°ç»„åˆå§‹åŒ–ä¼˜åŒ–å™¨
#         self.optim = torch.optim.Adam(param_groups, lr=CRITIC_PARA.lr)
#
#         print("--- Critic_GRU Optimizer Initialized with Parameter Groups ---")
#         print(f"  - GRU Params LR: {CRITIC_PARA.gru_lr}")
#         print(f"  - Other (MLP) Params LR: {CRITIC_PARA.lr}")
#         # <<< MODIFICATION END >>>
#
#         # ä¼˜åŒ–å™¨ç­‰è®¾ç½®
#         # self.optim = torch.optim.Adam(self.parameters(), CRITIC_PARA.lr)
#         self.critic_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
#                                                       end_factor=AGENTPARA.mini_lr / CRITIC_PARA.lr,
#                                                       total_iters=AGENTPARA.MAX_EXE_NUM)
#         self.to(CRITIC_PARA.device)
#
#     def forward(self, obs, hidden_state):
#         """
#         GRU Critic çš„å‰å‘ä¼ æ’­ã€‚
#         åŒæ ·æ”¯æŒå•æ­¥å’Œåºåˆ—è¾“å…¥ã€‚
#         """
#         obs_tensor = check(obs).to(**CRITIC_PARA.tpdv)
#         is_sequence = obs_tensor.dim() == 3
#
#         if not is_sequence:
#             obs_tensor = obs_tensor.unsqueeze(1)
#         # # 1. MLP ç‰¹å¾æå–
#         # base_features = self.network_base(obs_tensor)
#         # # 2. GRU åºåˆ—å¤„ç†
#         # gru_out, new_hidden = self.gru(base_features, hidden_state)
#         #
#         # if not is_sequence:
#         #     gru_out = gru_out.squeeze(1)
#         # # 3. è¾“å‡ºå¤´è®¡ç®—ä»·å€¼
#         # value = self.fc_out(gru_out)
#
#         # 1. [æ–°æµç¨‹] åŸå§‹çŠ¶æ€åºåˆ—é¦–å…ˆé€šè¿‡ GRU
#         gru_out, new_hidden = self.gru(obs_tensor, hidden_state)
#
#         # # 2. ğŸ’¥ [æ–°æµç¨‹] å°† GRU çš„è¾“å‡ºé€šè¿‡æ–°å¢çš„ LayerNorm
#         # normed_gru_out = self.mlp_input_layernorm(gru_out)
#         # # 3. [æ–°æµç¨‹] GRU çš„è¾“å‡ºï¼ˆè®°å¿†å‘é‡ï¼‰å†é€šè¿‡ MLP è¿›è¡Œç‰¹å¾æå–
#         # base_features = self.network_base(normed_gru_out)  # MLP çš„è¾“å…¥æ˜¯å½’ä¸€åŒ–åçš„ gru_out
#
#         # 2. [æ–°æµç¨‹] GRU çš„è¾“å‡ºå†é€šè¿‡ MLP
#         base_features = self.network_base(gru_out)
#
#         if not is_sequence:
#             base_features = base_features.squeeze(1)
#
#         # 3. [æ–°æµç¨‹] MLP çš„è¾“å‡ºé€å…¥è¾“å‡ºå¤´è®¡ç®—ä»·å€¼
#         value = self.fc_out(base_features)
#         return value, new_hidden
#
# # ==============================================================================
# # <<< æ–°æ¶æ„ >>>: å®šä¹‰åŸºäº MLP -> GRU çš„ Actor
# #                       [ğŸ’¥ æ–°ç»“æ„: å…±äº«MLP -> GRU -> å¡”æ¥¼MLP -> Heads]
# # ==============================================================================
#
# class Actor_GRU(Module):
#     """
#     Actor ç½‘ç»œ (ç­–ç•¥ç½‘ç»œ) - [æ··åˆæ¶æ„: MLP -> GRU]
#     ç»“æ„ä¸º: å…±äº«MLPåŸºåº§ -> GRU åºåˆ—å¤„ç† -> ä¸“ç”¨MLPå¡”æ¥¼ -> ç‹¬ç«‹åŠ¨ä½œå¤´ã€‚
#     """
#
#     def __init__(self):
#         super(Actor_GRU, self).__init__()
#         self.input_dim = ACTOR_PARA.input_dim
#         self.log_std_min = -20.0
#         self.log_std_max = 2.0
#         self.rnn_hidden_size = RNN_HIDDEN_SIZE
#
#         # --- 1. å®šä¹‰ GRU ä¹‹å‰çš„å…±äº« MLP ç‰¹å¾æå–å™¨ (Pre-GRU MLP) ---
#         # å‡è®¾æˆ‘ä»¬ä½¿ç”¨ model_layer_dim çš„å‰ä¸¤å±‚ä½œä¸º Pre-GRU MLP
#         # ä¾‹å¦‚ï¼Œå¦‚æœ model_layer_dim = [256, 256, 256]ï¼Œè¿™é‡Œå°±æ˜¯ [256, 256]
#         pre_gru_mlp_layers = 2
#         pre_gru_dims = ACTOR_PARA.model_layer_dim[:pre_gru_mlp_layers]  # -> [256, 256]
#
#         self.pre_gru_mlp = Sequential()
#         mlp_input_dim = self.input_dim
#         for i, dim in enumerate(pre_gru_dims):
#             self.pre_gru_mlp.add_module(f'pre_gru_fc_{i}', Linear(mlp_input_dim, dim))
#             self.pre_gru_mlp.add_module(f'pre_gru_leakyrelu_{i}', LeakyReLU())
#             mlp_input_dim = dim
#
#         # Pre-GRU MLP çš„è¾“å‡ºç»´åº¦ï¼Œå°†ä½œä¸º GRU çš„è¾“å…¥ç»´åº¦
#         pre_gru_output_dim = pre_gru_dims[-1] if pre_gru_dims else self.input_dim
#
#         # # --- æ–°å¢: GRU å‰çš„å½’ä¸€åŒ– ---
#         # self.ln_pre_gru = LayerNorm(pre_gru_output_dim)
#
#         # --- 2. GRU å±‚ ---
#         # GRU çš„è¾“å…¥ç»´åº¦ç°åœ¨æ˜¯ Pre-GRU MLP çš„è¾“å‡ºç»´åº¦
#         self.gru = GRU(pre_gru_output_dim, self.rnn_hidden_size, batch_first=True)
#
#         # # --- æ–°å¢: GRU åçš„å½’ä¸€åŒ– ---
#         # self.ln_post_gru = LayerNorm(self.rnn_hidden_size)
#
#         # --- 3. å®šä¹‰ GRU ä¹‹åçš„ MLP å¡”æ¥¼ (Post-GRU Towers) ---
#         # è¿™éƒ¨åˆ†ä¸ä½ åŸæœ‰çš„ Actor_GRU ç±»ä¼¼ï¼Œä½†è¾“å…¥ç»´åº¦æ˜¯ GRU çš„ hidden_size
#         post_gru_dims = ACTOR_PARA.model_layer_dim[pre_gru_mlp_layers:]  # -> [256]
#
#         # è¿ç»­åŠ¨ä½œå¡”æ¥¼
#         self.continuous_tower = Sequential()
#         tower_input_dim = self.rnn_hidden_size
#         for i, dim in enumerate(post_gru_dims):
#             self.continuous_tower.add_module(f'cont_tower_fc_{i}', Linear(tower_input_dim, dim))
#             self.continuous_tower.add_module(f'cont_tower_leakyrelu_{i}', LeakyReLU())
#             tower_input_dim = dim
#         continuous_tower_output_dim = post_gru_dims[-1] if post_gru_dims else self.rnn_hidden_size
#
#         # ç¦»æ•£åŠ¨ä½œå¡”æ¥¼ (å¯ä»¥å’Œè¿ç»­å¡”æ¥¼ç»“æ„ç›¸åŒæˆ–ä¸åŒ)
#         self.discrete_tower = Sequential()
#         tower_input_dim = self.rnn_hidden_size
#         for i, dim in enumerate(post_gru_dims):
#             self.discrete_tower.add_module(f'disc_tower_fc_{i}', Linear(tower_input_dim, dim))
#             self.discrete_tower.add_module(f'disc_tower_leakyrelu_{i}', LeakyReLU())
#             tower_input_dim = dim
#         discrete_tower_output_dim = post_gru_dims[-1] if post_gru_dims else self.rnn_hidden_size
#
#         # --- 4. å®šä¹‰æœ€ç»ˆçš„è¾“å‡ºå¤´ (Heads) ---
#         self.mu_head = Linear(continuous_tower_output_dim, CONTINUOUS_DIM)
#         self.discrete_head = Linear(discrete_tower_output_dim, TOTAL_DISCRETE_LOGITS)
#         self.log_std_param = torch.nn.Parameter(torch.full((1, CONTINUOUS_DIM), 0.0))
#
#         # --- å¿…é¡»æ·»åŠ è¿™è¡Œ ---
#         self.apply(init_weights)
#
#         # --- 5. ä¼˜åŒ–å™¨è®¾ç½® (å¯ä»¥ä¿æŒä¸å˜) ---
#         # ä»ç„¶å¯ä»¥å°† GRU å‚æ•°å’Œå…¶ä»– MLP å‚æ•°åˆ†å¼€è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡
#         gru_params = list(self.gru.parameters())
#         other_params = (
#                 list(self.pre_gru_mlp.parameters()) +
#                 list(self.continuous_tower.parameters()) +
#                 list(self.discrete_tower.parameters()) +
#                 list(self.mu_head.parameters()) +
#                 list(self.discrete_head.parameters()) +
#                 [self.log_std_param]
#         )
#
#         param_groups = [
#             {'params': gru_params, 'lr': ACTOR_PARA.gru_lr},
#             {'params': other_params, 'lr': ACTOR_PARA.lr}
#         ]
#         self.optim = torch.optim.Adam(param_groups)
#         self.actor_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
#                                                      end_factor=AGENTPARA.mini_lr / ACTOR_PARA.lr,
#                                                      total_iters=AGENTPARA.MAX_EXE_NUM)
#         self.to(ACTOR_PARA.device)
#
#     def forward(self, obs, hidden_state):
#         obs_tensor = check(obs).to(**ACTOR_PARA.tpdv)
#         is_sequence = obs_tensor.dim() == 3
#         if not is_sequence:
#             obs_tensor = obs_tensor.unsqueeze(1)
#
#         # 1. åŸå§‹çŠ¶æ€åºåˆ—é¦–å…ˆé€šè¿‡ Pre-GRU MLP è¿›è¡Œç‰¹å¾æå–
#         # Sequential ä¼šè‡ªåŠ¨åœ°å°† MLP åº”ç”¨äºåºåˆ—çš„æœ€åä¸€ä¸ªç»´åº¦
#         # è¾“å…¥: (batch, seq_len, features) -> è¾“å‡º: (batch, seq_len, pre_gru_output_dim)
#         features_sequence = self.pre_gru_mlp(obs_tensor)
#
#         # # --- åº”ç”¨ LayerNorm ---
#         # features_sequence = self.ln_pre_gru(features_sequence)
#
#         # 2. å°†æå–å‡ºçš„ç‰¹å¾åºåˆ—é€å…¥ GRU
#         # è¾“å…¥: (batch, seq_len, pre_gru_output_dim) -> è¾“å‡º: (batch, seq_len, rnn_hidden_size)
#         gru_out, new_hidden = self.gru(features_sequence, hidden_state)
#
#         # # --- åº”ç”¨ LayerNorm ---
#         # gru_out = self.ln_post_gru(gru_out)
#
#         # 3. GRU çš„è¾“å‡ºè¢«åˆ†åˆ«é€å…¥ä¸¤ä¸ªä¸“ç”¨å¡”æ¥¼
#         continuous_features = self.continuous_tower(gru_out)
#         discrete_features = self.discrete_tower(gru_out)
#
#         # 4. å¦‚æœæ˜¯å•æ­¥è¾“å…¥ï¼Œå‹ç¼©ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…å¤´éƒ¨
#         if not is_sequence:
#             continuous_features = continuous_features.squeeze(1)
#             discrete_features = discrete_features.squeeze(1)
#
#         # 5. æ¯ä¸ªå¤´éƒ¨æ¥æ”¶æ¥è‡ªå…¶ä¸“å±å¡”æ¥¼çš„ç‰¹å¾
#         mu = self.mu_head(continuous_features)
#         all_disc_logits = self.discrete_head(discrete_features)
#
#         # --- åç»­çš„åˆ†å¸ƒåˆ›å»ºå’Œæ©ç é€»è¾‘ä¸åŸç‰ˆ Actor_GRU å®Œå…¨ç›¸åŒ ---
#         # ... (æ­¤å¤„çœç•¥ä¸ Actor_GRU ä¸­å®Œå…¨ç›¸åŒçš„æ©ç å’Œåˆ†å¸ƒåˆ›å»ºä»£ç ) ...
#         split_sizes = list(DISCRETE_DIMS.values())
#         logits_parts = torch.split(all_disc_logits, split_sizes, dim=-1)
#         trigger_logits, salvo_size_logits, num_groups_logits, inter_interval_logits = logits_parts
#
#         has_flares_info = obs_tensor[..., 9] # åŸä¸º obs_tensor[..., 11]
#         mask = (has_flares_info == 0)
#         trigger_logits_masked = trigger_logits.clone()
#         if torch.any(mask):
#             if mask.dim() < trigger_logits_masked.dim():
#                 mask = mask.unsqueeze(-1)
#             trigger_logits_masked[mask] = torch.finfo(torch.float32).min
#
#         # (çœç•¥å±‚æ¬¡åŒ–æ§åˆ¶é€»è¾‘ï¼Œå› ä¸ºå’ŒåŸæ¥ä¸€æ ·)
#         trigger_probs = torch.sigmoid(trigger_logits_masked)
#         no_trigger_mask = (trigger_probs < 0.5).squeeze(-1)
#         salvo_size_logits_masked = salvo_size_logits.clone()
#         num_groups_logits_masked = num_groups_logits.clone()
#         inter_interval_logits_masked = inter_interval_logits.clone()
#         if torch.any(no_trigger_mask):
#             INF = 1e6
#             NEG_INF = -1e6
#             for logits_tensor in [salvo_size_logits_masked, num_groups_logits_masked, inter_interval_logits_masked]:
#                 logits_sub = logits_tensor[no_trigger_mask]
#                 if logits_sub.numel() > 0:
#                     logits_sub[:] = NEG_INF
#                     logits_sub[:, 0] = INF
#                     logits_tensor[no_trigger_mask] = logits_sub
#
#         log_std = torch.clamp(self.log_std_param, self.log_std_min, self.log_std_max)
#         std = torch.exp(log_std).expand_as(mu)
#         continuous_base_dist = Normal(mu, std)
#
#         trigger_dist = Bernoulli(logits=trigger_logits_masked.squeeze(-1))
#         salvo_size_dist = Categorical(logits=salvo_size_logits_masked)
#         num_groups_dist = Categorical(logits=num_groups_logits_masked)
#         inter_interval_dist = Categorical(logits=inter_interval_logits_masked)
#
#         distributions = {
#             'continuous': continuous_base_dist,
#             'trigger': trigger_dist,
#             'salvo_size': salvo_size_dist,
#             'num_groups': num_groups_dist,
#             'inter_interval': inter_interval_dist
#         }
#
#         return distributions, new_hidden
#
#
# # ==============================================================================
# # <<< æ–°æ¶æ„ >>>: å®šä¹‰åŸºäº MLP -> GRU çš„ Critic
# #                       [ğŸ’¥ æ–°ç»“æ„: å…±äº«MLP -> GRU -> MLP -> Head]
# # ==============================================================================
#
# class Critic_GRU(Module):
#     """
#     Critic ç½‘ç»œ (ä»·å€¼ç½‘ç»œ) - [æ··åˆæ¶æ„: MLP -> GRU]
#     ç»“æ„ä¸º: å…±äº«MLPç‰¹å¾æå– -> GRU åºåˆ—å¤„ç† -> MLP -> è¾“å‡ºå¤´ã€‚
#     ä¸ Actor_MLP_GRU çš„ä¸»å¹²ç»“æ„ä¿æŒä¸€è‡´ã€‚
#     """
#
#     def __init__(self):
#         super(Critic_GRU, self).__init__()
#         self.input_dim = CRITIC_PARA.input_dim
#         self.output_dim = CRITIC_PARA.output_dim
#         self.rnn_hidden_size = RNN_HIDDEN_SIZE
#
#         # --- 1. å®šä¹‰ GRU ä¹‹å‰çš„å…±äº« MLP ç‰¹å¾æå–å™¨ (Pre-GRU MLP) ---
#         # ä½¿ç”¨ Critic é…ç½®ä¸­çš„ MLP å±‚å®šä¹‰
#         pre_gru_mlp_layers = 2  # ä¸ Actor ä¿æŒä¸€è‡´
#         pre_gru_dims = CRITIC_PARA.model_layer_dim[:pre_gru_mlp_layers]
#
#         self.pre_gru_mlp = Sequential()
#         mlp_input_dim = self.input_dim
#         for i, dim in enumerate(pre_gru_dims):
#             self.pre_gru_mlp.add_module(f'pre_gru_fc_{i}', Linear(mlp_input_dim, dim))
#             self.pre_gru_mlp.add_module(f'pre_gru_leakyrelu_{i}', LeakyReLU())
#             mlp_input_dim = dim
#
#         pre_gru_output_dim = pre_gru_dims[-1] if pre_gru_dims else self.input_dim
#
#         # # --- æ–°å¢: GRU å‰çš„å½’ä¸€åŒ– ---
#         # self.ln_pre_gru = LayerNorm(pre_gru_output_dim)
#
#         # --- 2. GRU å±‚ ---
#         self.gru = GRU(pre_gru_output_dim, self.rnn_hidden_size, batch_first=True)
#
#         # # --- æ–°å¢: GRU åçš„å½’ä¸€åŒ– ---
#         # self.ln_post_gru = LayerNorm(self.rnn_hidden_size)
#
#         # --- 3. å®šä¹‰ GRU ä¹‹åçš„ MLP (Post-GRU MLP) ---
#         post_gru_dims = CRITIC_PARA.model_layer_dim[pre_gru_mlp_layers:]
#
#         self.post_gru_mlp = Sequential()
#         tower_input_dim = self.rnn_hidden_size
#         for i, dim in enumerate(post_gru_dims):
#             self.post_gru_mlp.add_module(f'post_gru_fc_{i}', Linear(tower_input_dim, dim))
#             self.post_gru_mlp.add_module(f'post_gru_leakyrelu_{i}', LeakyReLU())
#             tower_input_dim = dim
#
#         post_gru_output_dim = post_gru_dims[-1] if post_gru_dims else self.rnn_hidden_size
#
#         # --- 4. æœ€ç»ˆçš„è¾“å‡ºå¤´ (Head) ---
#         self.fc_out = Linear(post_gru_output_dim, self.output_dim)
#
#         # --- å¿…é¡»æ·»åŠ è¿™è¡Œ ---
#         self.apply(init_weights)
#
#         # --- 5. ä¼˜åŒ–å™¨è®¾ç½® (ä¸ Actor ç±»ä¼¼ï¼Œåˆ†ç¦» GRU å’Œå…¶ä»–å‚æ•°) ---
#         gru_params = list(self.gru.parameters())
#         other_params = (
#                 list(self.pre_gru_mlp.parameters()) +
#                 list(self.post_gru_mlp.parameters()) +
#                 list(self.fc_out.parameters())
#         )
#
#         param_groups = [
#             {'params': gru_params, 'lr': CRITIC_PARA.gru_lr},
#             {'params': other_params, 'lr': CRITIC_PARA.lr}
#         ]
#         self.optim = torch.optim.Adam(param_groups)
#         self.critic_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
#                                                       end_factor=AGENTPARA.mini_lr / CRITIC_PARA.lr,
#                                                       total_iters=AGENTPARA.MAX_EXE_NUM)
#         self.to(CRITIC_PARA.device)
#
#     def forward(self, obs, hidden_state):
#         obs_tensor = check(obs).to(**CRITIC_PARA.tpdv)
#         is_sequence = obs_tensor.dim() == 3
#         if not is_sequence:
#             obs_tensor = obs_tensor.unsqueeze(1)
#
#         # 1. åŸå§‹çŠ¶æ€åºåˆ—é€šè¿‡ Pre-GRU MLP
#         features_sequence = self.pre_gru_mlp(obs_tensor)
#
#         # # --- åº”ç”¨ LayerNorm ---
#         # features_sequence = self.ln_pre_gru(features_sequence)
#
#         # 2. ç‰¹å¾åºåˆ—é€å…¥ GRU
#         gru_out, new_hidden = self.gru(features_sequence, hidden_state)
#
#         # # --- åº”ç”¨ LayerNorm ---
#         # gru_out = self.ln_post_gru(gru_out)
#
#         # 3. GRU è¾“å‡ºé€šè¿‡ Post-GRU MLP
#         post_gru_features = self.post_gru_mlp(gru_out)
#
#         # å¤„ç†å•æ­¥è¾“å…¥çš„æƒ…å†µ
#         if not is_sequence:
#             post_gru_features = post_gru_features.squeeze(1)
#
#         # 4. MLP è¾“å‡ºé€å…¥è¾“å‡ºå¤´è®¡ç®—ä»·å€¼
#         value = self.fc_out(post_gru_features)
#
#         return value, new_hidden


# # ==============================================================================
# # <<< æ–°æ¶æ„ >>>: å®šä¹‰åŸºäº 128 -> GRU -> 128 çš„ Actor å’Œ Critic
# #                       [ğŸ’¥ æ–°ç»“æ„: MLP -> GRU -> å…±äº«MLP -> å¡”æ¥¼MLP -> Heads]
# # ==============================================================================
#
# class Actor_GRU(Module):
#     """
#     Actor ç½‘ç»œ (ç­–ç•¥ç½‘ç»œ) - [è‡ªå®šä¹‰æ··åˆæ¶æ„: 128 -> GRU -> 128 (å…±äº«) -> 128 (å¡”æ¥¼)]
#     """
#
#     def __init__(self):
#         super(Actor_GRU, self).__init__()
#         self.input_dim = ACTOR_PARA.input_dim
#         self.log_std_min = -20.0
#         self.log_std_max = 2.0
#         self.rnn_hidden_size = 128  # GRUçš„éšè—å±‚å¤§å°å›ºå®šä¸º128
#
#         # å®šä¹‰ç½‘ç»œå„éƒ¨åˆ†çš„ç»´åº¦
#         pre_gru_dim = 128
#         post_gru_shared_dim = 128
#         tower_dim = 128
#
#         # --- 1. Pre-GRU MLP (1å±‚, è¾“å‡º128) ---
#         self.pre_gru_mlp = Sequential(
#             Linear(self.input_dim, pre_gru_dim),
#             LeakyReLU()
#         )
#
#         # --- 2. GRU å±‚ (è¾“å…¥128, éšè—128) ---
#         self.gru = GRU(pre_gru_dim, self.rnn_hidden_size, batch_first=True)
#
#         # --- 3. Post-GRU å…±äº« MLP (1å±‚, è¾“å‡º128) ---
#         self.post_gru_shared_mlp = Sequential(
#             Linear(self.rnn_hidden_size, post_gru_shared_dim),
#             LeakyReLU()
#         )
#
#         # --- 4. ä¸“ç”¨ MLP å¡”æ¥¼ (æ¯æ¡è·¯1å±‚, è¾“å‡º128) ---
#         # è¿ç»­åŠ¨ä½œå¡”æ¥¼
#         self.continuous_tower = Sequential(
#             Linear(post_gru_shared_dim, tower_dim),
#             LeakyReLU()
#         )
#         # ç¦»æ•£åŠ¨ä½œå¡”æ¥¼
#         self.discrete_tower = Sequential(
#             Linear(post_gru_shared_dim, tower_dim),
#             LeakyReLU()
#         )
#
#         # --- 5. æœ€ç»ˆçš„è¾“å‡ºå¤´ (Heads) ---
#         self.mu_head = Linear(tower_dim, CONTINUOUS_DIM)
#         self.discrete_head = Linear(tower_dim, TOTAL_DISCRETE_LOGITS)
#         self.log_std_param = torch.nn.Parameter(torch.full((1, CONTINUOUS_DIM), 0.0))
#
#         # --- 6. ä¼˜åŒ–å™¨è®¾ç½® ---
#         gru_params = list(self.gru.parameters())
#         other_params = (
#                 list(self.pre_gru_mlp.parameters()) +
#                 list(self.post_gru_shared_mlp.parameters()) +
#                 list(self.continuous_tower.parameters()) +
#                 list(self.discrete_tower.parameters()) +
#                 list(self.mu_head.parameters()) +
#                 list(self.discrete_head.parameters()) +
#                 [self.log_std_param]
#         )
#         param_groups = [
#             {'params': gru_params, 'lr': ACTOR_PARA.gru_lr},
#             {'params': other_params, 'lr': ACTOR_PARA.lr}
#         ]
#         self.optim = torch.optim.Adam(param_groups)
#         self.actor_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
#                                                      end_factor=AGENTPARA.mini_lr / ACTOR_PARA.lr,
#                                                      total_iters=AGENTPARA.MAX_EXE_NUM)
#         self.to(ACTOR_PARA.device)
#
#     def forward(self, obs, hidden_state):
#         obs_tensor = check(obs).to(**ACTOR_PARA.tpdv)
#         is_sequence = obs_tensor.dim() == 3
#         if not is_sequence:
#             obs_tensor = obs_tensor.unsqueeze(1)
#
#         # 1. åŸå§‹çŠ¶æ€åºåˆ—é€šè¿‡ Pre-GRU MLP
#         features1 = self.pre_gru_mlp(obs_tensor)
#
#         # 2. ç‰¹å¾åºåˆ—é€å…¥ GRU
#         gru_out, new_hidden = self.gru(features1, hidden_state)
#
#         # 3. GRU è¾“å‡ºé€šè¿‡ Post-GRU å…±äº« MLP
#         shared_features = self.post_gru_shared_mlp(gru_out)
#
#         # 4. å…±äº«ç‰¹å¾è¢«åˆ†åˆ«é€å…¥ä¸¤ä¸ªä¸“ç”¨å¡”æ¥¼
#         continuous_features = self.continuous_tower(shared_features)
#         discrete_features = self.discrete_tower(shared_features)
#
#         # 5. å¦‚æœæ˜¯å•æ­¥è¾“å…¥ï¼Œå‹ç¼©ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…å¤´éƒ¨
#         if not is_sequence:
#             continuous_features = continuous_features.squeeze(1)
#             discrete_features = discrete_features.squeeze(1)
#
#         # 6. æ¯ä¸ªå¤´éƒ¨æ¥æ”¶æ¥è‡ªå…¶ä¸“å±å¡”æ¥¼çš„ç‰¹å¾
#         mu = self.mu_head(continuous_features)
#         all_disc_logits = self.discrete_head(discrete_features)
#
#         # --- åç»­çš„åˆ†å¸ƒåˆ›å»ºå’Œæ©ç é€»è¾‘ä¸ä¹‹å‰å®Œå…¨ç›¸åŒ ---
#         # ... (æ­¤å¤„çœç•¥ä¸ä¹‹å‰ Actor_GRU ä¸­å®Œå…¨ç›¸åŒçš„æ©ç å’Œåˆ†å¸ƒåˆ›å»ºä»£ç ) ...
#         split_sizes = list(DISCRETE_DIMS.values())
#         logits_parts = torch.split(all_disc_logits, split_sizes, dim=-1)
#         trigger_logits, salvo_size_logits, num_groups_logits, inter_interval_logits = logits_parts
#
#         has_flares_info = obs_tensor[..., 7]
#         mask = (has_flares_info == 0)
#         trigger_logits_masked = trigger_logits.clone()
#         if torch.any(mask):
#             if mask.dim() < trigger_logits_masked.dim():
#                 mask = mask.unsqueeze(-1)
#             trigger_logits_masked[mask] = torch.finfo(torch.float32).min
#
#         trigger_probs = torch.sigmoid(trigger_logits_masked)
#         no_trigger_mask = (trigger_probs < 0.5).squeeze(-1)
#         salvo_size_logits_masked = salvo_size_logits.clone()
#         num_groups_logits_masked = num_groups_logits.clone()
#         inter_interval_logits_masked = inter_interval_logits.clone()
#         if torch.any(no_trigger_mask):
#             INF = 1e6
#             NEG_INF = -1e6
#             for logits_tensor in [salvo_size_logits_masked, num_groups_logits_masked, inter_interval_logits_masked]:
#                 logits_sub = logits_tensor[no_trigger_mask]
#                 if logits_sub.numel() > 0:
#                     logits_sub[:] = NEG_INF
#                     logits_sub[:, 0] = INF
#                     logits_tensor[no_trigger_mask] = logits_sub
#
#         log_std = torch.clamp(self.log_std_param, self.log_std_min, self.log_std_max)
#         std = torch.exp(log_std).expand_as(mu)
#         continuous_base_dist = Normal(mu, std)
#
#         trigger_dist = Bernoulli(logits=trigger_logits_masked.squeeze(-1))
#         salvo_size_dist = Categorical(logits=salvo_size_logits_masked)
#         num_groups_dist = Categorical(logits=num_groups_logits_masked)
#         inter_interval_dist = Categorical(logits=inter_interval_logits_masked)
#
#         distributions = {
#             'continuous': continuous_base_dist,
#             'trigger': trigger_dist,
#             'salvo_size': salvo_size_dist,
#             'num_groups': num_groups_dist,
#             'inter_interval': inter_interval_dist
#         }
#
#         return distributions, new_hidden
#
#
# class Critic_GRU(Module):
#     """
#     Critic ç½‘ç»œ (ä»·å€¼ç½‘ç»œ) - [è‡ªå®šä¹‰æ··åˆæ¶æ„]
#     ä¸ Actor çš„ä¸»å¹²ç»“æ„ä¿æŒä¸€è‡´ï¼Œä»¥å®ç°æ›´å¥½çš„ç‰¹å¾å…±äº«å’Œè¡¨ç¤ºå­¦ä¹ ã€‚
#     """
#
#     def __init__(self):
#         super(Critic_GRU, self).__init__()
#         self.input_dim = CRITIC_PARA.input_dim
#         self.output_dim = CRITIC_PARA.output_dim
#         self.rnn_hidden_size = 128  # ä¸ Actor ä¿æŒä¸€è‡´
#
#         # å®šä¹‰ç½‘ç»œå„éƒ¨åˆ†çš„ç»´åº¦
#         pre_gru_dim = 128
#         post_gru_shared_dim = 128
#         final_mlp_dim = 128
#
#         # --- 1. Pre-GRU MLP (ä¸ Actor ç»“æ„ç›¸åŒ) ---
#         self.pre_gru_mlp = Sequential(
#             Linear(self.input_dim, pre_gru_dim),
#             LeakyReLU()
#         )
#
#         # --- 2. GRU å±‚ (ä¸ Actor ç»“æ„ç›¸åŒ) ---
#         self.gru = GRU(pre_gru_dim, self.rnn_hidden_size, batch_first=True)
#
#         # --- 3. Post-GRU å…±äº« MLP (ä¸ Actor ç»“æ„ç›¸åŒ) ---
#         self.post_gru_shared_mlp = Sequential(
#             Linear(self.rnn_hidden_size, post_gru_shared_dim),
#             LeakyReLU()
#         )
#
#         # --- 4. æœ€ç»ˆçš„ä»·å€¼å¤„ç† MLP ---
#         self.final_mlp = Sequential(
#             Linear(post_gru_shared_dim, final_mlp_dim),
#             LeakyReLU()
#         )
#
#         # --- 5. æœ€ç»ˆçš„è¾“å‡ºå¤´ (Head) ---
#         self.fc_out = Linear(final_mlp_dim, self.output_dim)
#
#         # --- 6. ä¼˜åŒ–å™¨è®¾ç½® ---
#         gru_params = list(self.gru.parameters())
#         other_params = (
#                 list(self.pre_gru_mlp.parameters()) +
#                 list(self.post_gru_shared_mlp.parameters()) +
#                 list(self.final_mlp.parameters()) +
#                 list(self.fc_out.parameters())
#         )
#         param_groups = [
#             {'params': gru_params, 'lr': CRITIC_PARA.gru_lr},
#             {'params': other_params, 'lr': CRITIC_PARA.lr}
#         ]
#         self.optim = torch.optim.Adam(param_groups)
#         self.critic_scheduler = lr_scheduler.LinearLR(self.optim, start_factor=1.0,
#                                                       end_factor=AGENTPARA.mini_lr / CRITIC_PARA.lr,
#                                                       total_iters=AGENTPARA.MAX_EXE_NUM)
#         self.to(CRITIC_PARA.device)
#
#     def forward(self, obs, hidden_state):
#         obs_tensor = check(obs).to(**CRITIC_PARA.tpdv)
#         is_sequence = obs_tensor.dim() == 3
#         if not is_sequence:
#             obs_tensor = obs_tensor.unsqueeze(1)
#
#         # 1. åŸå§‹çŠ¶æ€åºåˆ—é€šè¿‡ Pre-GRU MLP
#         features1 = self.pre_gru_mlp(obs_tensor)
#
#         # 2. ç‰¹å¾åºåˆ—é€å…¥ GRU
#         gru_out, new_hidden = self.gru(features1, hidden_state)
#
#         # 3. GRU è¾“å‡ºé€šè¿‡ Post-GRU å…±äº« MLP
#         shared_features = self.post_gru_shared_mlp(gru_out)
#
#         # 4. å…±äº«ç‰¹å¾é€å…¥æœ€ç»ˆçš„MLP
#         final_features = self.final_mlp(shared_features)
#
#         # å¤„ç†å•æ­¥è¾“å…¥çš„æƒ…å†µ
#         if not is_sequence:
#             final_features = final_features.squeeze(1)
#
#         # 5. MLP è¾“å‡ºé€å…¥è¾“å‡ºå¤´è®¡ç®—ä»·å€¼
#         value = self.fc_out(final_features)
#
#         return value, new_hidden


# ==============================================================================
# PPO Agent ä¸»ç±»
# ==============================================================================

class PPO_continuous(object):
    """
    PPO æ™ºèƒ½ä½“ä¸»ç±»ã€‚
    é€šè¿‡ `use_rnn` æ ‡å¿—æ¥å†³å®šæ˜¯ä½¿ç”¨ MLP æ¨¡å‹è¿˜æ˜¯ GRU æ¨¡å‹ã€‚
    """
    def __init__(self, load_able: bool, model_dir_path: str = None, use_rnn: bool = False):
        super(PPO_continuous, self).__init__()
        # æ ¹æ® use_rnn æ ‡å¿—ï¼Œå®ä¾‹åŒ–å¯¹åº”çš„ Actor å’Œ Critic ç½‘ç»œ
        self.use_rnn = use_rnn
        if self.use_rnn:
            print("--- åˆå§‹åŒ– PPO Agent (ä½¿ç”¨ GRU æ¨¡å‹) ---")
            self.Actor = Actor_GRU()
            self.Critic = Critic_GRU()
        else:
            print("--- åˆå§‹åŒ– PPO Agent (ä½¿ç”¨ MLP æ¨¡å‹) ---")
            self.Actor = Actor()
            self.Critic = Critic()
        # å®ä¾‹åŒ–ç»éªŒå›æ”¾æ± ï¼Œå¹¶å‘ŠçŸ¥å®ƒæ˜¯å¦éœ€è¦å¤„ç† RNN éšè—çŠ¶æ€
        self.buffer = Buffer(use_rnn=self.use_rnn)
        # ä»é…ç½®ä¸­åŠ è½½ PPO ç®—æ³•çš„è¶…å‚æ•°
        self.gamma = AGENTPARA.gamma
        self.gae_lambda = AGENTPARA.lamda
        self.ppo_epoch = AGENTPARA.ppo_epoch
        self.total_steps = 0
        self.training_start_time = time.strftime("PPOGRU_%Y-%m-%d_%H-%M-%S")
        self.base_save_dir = "../../../../save/save_evade_fuza"
        win_rate_subdir = "èƒœç‡æ¨¡å‹"
        # ä¸ºæœ¬æ¬¡è¿è¡Œåˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„å­˜æ¡£æ–‡ä»¶å¤¹
        self.run_save_dir = os.path.join(self.base_save_dir, self.training_start_time)
        self.win_rate_dir = os.path.join(self.run_save_dir, win_rate_subdir)

        # å¦‚æœéœ€è¦åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if load_able:
            if model_dir_path:
                print(f"--- æ­£åœ¨ä»æŒ‡å®šæ–‡ä»¶å¤¹åŠ è½½æ¨¡å‹: {model_dir_path} ---")
                self.load_models_from_directory(model_dir_path)
            else:
                print("--- æœªæŒ‡å®šæ¨¡å‹æ–‡ä»¶å¤¹ï¼Œå°è¯•ä»é»˜è®¤æ–‡ä»¶å¤¹ 'test' åŠ è½½ ---")
                self.load_models_from_directory("../../../../test/test_evade")

    def load_models_from_directory(self, directory_path: str):
        # This function is correct, no changes needed.
        """ä»æŒ‡å®šç›®å½•åŠ è½½ Actor å’Œ Critic æ¨¡å‹çš„æƒé‡ã€‚"""
        if not os.path.isdir(directory_path):
            print(f"[é”™è¯¯] æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæä¾›çš„è·¯å¾„ '{directory_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶å¤¹ã€‚")
            return
        files = os.listdir(directory_path)
        # ä¼˜å…ˆå°è¯•åŠ è½½å¸¦æœ‰å‰ç¼€çš„æ¨¡å‹æ–‡ä»¶ (ä¾‹å¦‚ "1000_Actor.pkl")
        actor_files_with_prefix = [f for f in files if f.endswith("_Actor.pkl")]
        if len(actor_files_with_prefix) > 0:
            actor_filename = actor_files_with_prefix[0]
            prefix = actor_filename.replace("_Actor.pkl", "")
            critic_filename = f"{prefix}_Critic.pkl"
            print(f"  - æ£€æµ‹åˆ°å‰ç¼€ '{prefix}'ï¼Œå‡†å¤‡åŠ è½½æ¨¡å‹...")
            if critic_filename in files:
                actor_full_path = os.path.join(directory_path, actor_filename)
                critic_full_path = os.path.join(directory_path, critic_filename)
                try:
                    self.Actor.load_state_dict(torch.load(actor_full_path, map_location=ACTOR_PARA.device))
                    print(f"    - æˆåŠŸåŠ è½½ Actor: {actor_full_path}")
                    self.Critic.load_state_dict(torch.load(critic_full_path, map_location=CRITIC_PARA.device))
                    print(f"    - æˆåŠŸåŠ è½½ Critic: {critic_full_path}")
                    return
                except Exception as e:
                    print(f"    - [é”™è¯¯] åŠ è½½å¸¦å‰ç¼€çš„æ¨¡å‹æ—¶å¤±è´¥: {e}")
            else:
                print(f"    - [è­¦å‘Š] æ‰¾åˆ°äº† '{actor_filename}' ä½†æœªæ‰¾åˆ°å¯¹åº”çš„ '{critic_filename}'ã€‚")
        # å¦‚æœæ²¡æœ‰å¸¦å‰ç¼€çš„æ–‡ä»¶ï¼Œåˆ™å°è¯•åŠ è½½é»˜è®¤çš„ "Actor.pkl" å’Œ "Critic.pkl"
        if "Actor.pkl" in files and "Critic.pkl" in files:
            print("  - æ£€æµ‹åˆ°æ— å‰ç¼€æ ¼å¼ï¼Œå‡†å¤‡åŠ è½½ 'Actor.pkl' å’Œ 'Critic.pkl'...")
            actor_full_path = os.path.join(directory_path, "Actor.pkl")
            critic_full_path = os.path.join(directory_path, "Critic.pkl")
            try:
                self.Actor.load_state_dict(torch.load(actor_full_path, map_location=ACTOR_PARA.device))
                print(f"    - æˆåŠŸåŠ è½½ Actor: {actor_full_path}")
                self.Critic.load_state_dict(torch.load(critic_full_path, map_location=CRITIC_PARA.device))
                print(f"    - æˆåŠŸåŠ è½½ Critic: {critic_full_path}")
                return
            except Exception as e:
                print(f"    - [é”™è¯¯] åŠ è½½æ— å‰ç¼€æ¨¡å‹æ—¶å¤±è´¥: {e}")
        print(f"[é”™è¯¯] æ¨¡å‹åŠ è½½å¤±è´¥ï¼šåœ¨æ–‡ä»¶å¤¹ '{directory_path}' ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ Actor/Critic æ¨¡å‹å¯¹ã€‚")

    def scale_action(self, action_cont_tanh):
        """å°† tanh è¾“å‡ºçš„è¿ç»­åŠ¨ä½œ (-1, 1) ç¼©æ”¾åˆ°ç¯å¢ƒå®šä¹‰çš„å®é™…èŒƒå›´ã€‚"""
        lows = torch.tensor([ACTION_RANGES[k]['low'] for k in CONTINUOUS_ACTION_KEYS], **ACTOR_PARA.tpdv)
        highs = torch.tensor([ACTION_RANGES[k]['high'] for k in CONTINUOUS_ACTION_KEYS], **ACTOR_PARA.tpdv)
        scaled_action = lows + (action_cont_tanh + 1.0) * 0.5 * (highs - lows)
        return scaled_action

    def get_initial_hidden_states(self, batch_size=1):
        """ä¸º GRU æ¨¡å‹ç”Ÿæˆåˆå§‹çš„é›¶éšè—çŠ¶æ€ã€‚"""
        if not self.use_rnn:
            return None, None
        actor_hidden = torch.zeros((1, batch_size, self.Actor.rnn_hidden_size), device=ACTOR_PARA.device)
        critic_hidden = torch.zeros((1, batch_size, self.Critic.rnn_hidden_size), device=CRITIC_PARA.device)
        return actor_hidden, critic_hidden

    def store_experience(self, state, action, probs, value, reward, done, actor_hidden=None, critic_hidden=None):
        """å°†å•æ­¥ç»éªŒå­˜å‚¨åˆ° Buffer ä¸­ã€‚"""
        # æ£€æŸ¥ log_prob æ˜¯å¦åŒ…å«æ— æ•ˆå€¼ï¼ˆNaN æˆ– Infï¼‰
        if not np.all(np.isfinite(probs)):
            raise ValueError("åœ¨ log_prob ä¸­æ£€æµ‹åˆ° NaN/Infï¼")
        # å¦‚æœä½¿ç”¨ RNNï¼Œå¿…é¡»æä¾›éšè—çŠ¶æ€
        if self.use_rnn and (actor_hidden is None or critic_hidden is None):
            raise ValueError("ä½¿ç”¨ RNN æ¨¡å‹æ—¶å¿…é¡»å­˜å‚¨éšè—çŠ¶æ€ï¼")
        self.buffer.store_transition(state, value, action, probs, reward, done, actor_hidden, critic_hidden)

    def choose_action(self, state, actor_hidden, critic_hidden, deterministic=False):
        """
        æ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©åŠ¨ä½œã€‚
        :param deterministic: å¦‚æœä¸º Trueï¼Œåˆ™é€‰æ‹©æœ€å¯èƒ½çš„åŠ¨ä½œï¼ˆç”¨äºè¯„ä¼°ï¼‰ï¼Œå¦åˆ™è¿›è¡Œéšæœºé‡‡æ ·ï¼ˆç”¨äºè®­ç»ƒï¼‰ã€‚
        :return: A tuple containing the action for the environment, action to store in buffer,
                 log probability, state value, and new hidden states.
        """
        state_tensor = torch.as_tensor(state, dtype=torch.float32, device=ACTOR_PARA.device)
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦æ˜¯æ‰¹å¤„ç†æ•°æ®
        is_batch = state_tensor.dim() > 1
        if not is_batch:
            state_tensor = state_tensor.unsqueeze(0)

        with torch.no_grad():# åœ¨æ­¤å—ä¸­ä¸è®¡ç®—æ¢¯åº¦
            if self.use_rnn:
                # GRU æ¨¡å‹éœ€è¦ä¼ å…¥éšè—çŠ¶æ€
                value, new_critic_hidden = self.Critic(state_tensor, critic_hidden)
                dists, new_actor_hidden = self.Actor(state_tensor, actor_hidden)
            else:
                # MLP æ¨¡å‹ä¸éœ€è¦éšè—çŠ¶æ€
                value = self.Critic(state_tensor)
                dists = self.Actor(state_tensor)
                new_critic_hidden, new_actor_hidden = None, None
            # ä»è¿ç»­åŠ¨ä½œåˆ†å¸ƒä¸­é‡‡æ ·
            continuous_base_dist = dists['continuous']
            # u æ˜¯æ­£æ€åˆ†å¸ƒçš„åŸå§‹æ ·æœ¬ï¼Œtanh(u) æ˜¯ä¸ºäº†é™åˆ¶èŒƒå›´å¹¶å¼•å…¥éçº¿æ€§
            u = continuous_base_dist.mean if deterministic else continuous_base_dist.rsample()
            action_cont_tanh = torch.tanh(u)
            log_prob_cont = continuous_base_dist.log_prob(u).sum(dim=-1)
            # ä»æ‰€æœ‰ç¦»æ•£åŠ¨ä½œåˆ†å¸ƒä¸­é‡‡æ ·
            sampled_actions_dict = {}
            for key, dist in dists.items():
                if key == 'continuous': continue
                if deterministic:
                    if isinstance(dist, Categorical): # åˆ†ç±»åˆ†å¸ƒï¼šå–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«
                        sampled_actions_dict[key] = torch.argmax(dist.probs, dim=-1)
                    else: # ä¼¯åŠªåˆ©åˆ†å¸ƒï¼šå–æ¦‚ç‡å¤§äº0.5çš„
                        sampled_actions_dict[key] = (dist.probs > 0.5).float()
                        # sampled_actions_dict[key] = dist.sample()
                else:
                    sampled_actions_dict[key] = dist.sample()
            # è®¡ç®—æ€»çš„å¯¹æ•°æ¦‚ç‡
            log_prob_disc = sum(dists[key].log_prob(act) for key, act in sampled_actions_dict.items())
            total_log_prob = log_prob_cont + log_prob_disc
            # å‡†å¤‡è¦å­˜å‚¨åœ¨ Buffer ä¸­çš„åŠ¨ä½œï¼ˆè¿ç»­éƒ¨åˆ†æ˜¯åŸå§‹æ ·æœ¬ uï¼Œç¦»æ•£éƒ¨åˆ†æ˜¯ç±»åˆ«ç´¢å¼•ï¼‰
            action_disc_to_store = torch.stack(list(sampled_actions_dict.values()), dim=-1).float()
            action_to_store = torch.cat([u, action_disc_to_store], dim=-1)
            # å‡†å¤‡è¦å‘é€ç»™ç¯å¢ƒçš„åŠ¨ä½œï¼ˆè¿ç»­éƒ¨åˆ†æ˜¯ç¼©æ”¾åçš„åŠ¨ä½œï¼Œç¦»æ•£éƒ¨åˆ†æ˜¯ç±»åˆ«ç´¢å¼•ï¼‰
            env_action_cont = self.scale_action(action_cont_tanh)
            final_env_action_tensor = torch.cat([env_action_cont, action_disc_to_store], dim=-1)
            # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸º numpy æ•°ç»„
            value_np = value.cpu().numpy()
            action_to_store_np = action_to_store.cpu().numpy()
            log_prob_to_store_np = total_log_prob.cpu().numpy()
            final_env_action_np = final_env_action_tensor.cpu().numpy()
            # å¦‚æœè¾“å…¥ä¸æ˜¯æ‰¹å¤„ç†ï¼Œåˆ™ç§»é™¤æ‰¹æ¬¡ç»´åº¦
            if not is_batch:
                final_env_action_np = final_env_action_np[0]
                action_to_store_np = action_to_store_np[0]
                log_prob_to_store_np = log_prob_to_store_np[0]
                value_np = value_np[0]

        return final_env_action_np, action_to_store_np, log_prob_to_store_np, value_np, new_actor_hidden, new_critic_hidden

    def cal_gae(self, states, values, actions, probs, rewards, dones):
        """è®¡ç®—å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡ (Generalized Advantage Estimation, GAE)ã€‚"""
        advantage = np.zeros(len(rewards), dtype=np.float32)
        gae = 0
        # ä»åå‘å‰éå†è½¨è¿¹
        for t in reversed(range(len(rewards))):
            # è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€çš„ä»·å€¼ï¼Œå¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œåˆ™ä¸º 0
            next_value = values[t + 1] if t < len(rewards) - 1 else 0.0
            # done_mask ç”¨äºåœ¨å›åˆç»“æŸæ—¶åˆ‡æ–­ä»·å€¼çš„ä¼ æ’­
            done_mask = 1.0 - int(dones[t])
            # è®¡ç®— TD-error (delta)
            delta = rewards[t] + self.gamma * next_value * done_mask - values[t]
            # é€’å½’è®¡ç®— GAE
            gae = delta + self.gamma * self.gae_lambda * done_mask * gae
            advantage[t] = gae
        return advantage

    def learn(self):
        """
        æ‰§è¡Œ PPO çš„å­¦ä¹ å’Œæ›´æ–°æ­¥éª¤ã€‚å·²é€‚é… RNN æ¨¡å¼å¹¶ä¿®æ­£æ‰€æœ‰é€»è¾‘å’Œç»´åº¦é”™è¯¯ã€‚
        """
        # å¦‚æœ Buffer ä¸­çš„æ•°æ®ä¸è¶³ä¸€ä¸ªæ‰¹æ¬¡ï¼Œåˆ™è·³è¿‡å­¦ä¹ 
        if self.buffer.get_buffer_size() < BUFFERPARA.BATCH_SIZE:
            print(
                f"  [Info] Buffer size ({self.buffer.get_buffer_size()}) < batch size ({BUFFERPARA.BATCH_SIZE}). Skipping.")
            return None
        # 1. æ•°æ®å‡†å¤‡
        states, values, actions, old_probs, rewards, dones, _, __ = self.buffer.get_all_data()
        advantages = self.cal_gae(states, values, actions, old_probs, rewards, dones)
        # âœ… ç¡®ä¿ values æ˜¯ä¸€ç»´æ•°ç»„ï¼Œä¸ advantages å¯¹é½
        values = np.squeeze(values)  # ç§»é™¤å¤šä½™ç»´åº¦ï¼Œæ¯”å¦‚ (N,1) â†’ (N,)

        # âœ… ä¿è¯ returns ä¸ values å½¢çŠ¶ä¸€è‡´
        # returns (å³ G_t) æ˜¯ä¼˜åŠ¿å‡½æ•°çš„ unbiased estimator
        returns = advantages + values
        # ç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŸå¤±å’ŒæŒ‡æ ‡
        train_info = {'critic_loss': [], 'actor_loss': [], 'dist_entropy': [],'entropy_cont': [], 'adv_targ': [], 'ratio': []}
        # 2. PPO è®­ç»ƒå¾ªç¯
        for _ in range(self.ppo_epoch):
            # æ ¹æ®æ˜¯å¦ä½¿ç”¨ RNNï¼Œé€‰æ‹©ä¸åŒçš„æ‰¹æ¬¡ç”Ÿæˆå™¨
            if self.use_rnn:
                # ä¸º RNN ç”Ÿæˆè¿ç»­çš„åºåˆ—æ‰¹æ¬¡
                batch_generator = self.buffer.generate_sequence_batches(
                    SEQUENCE_LENGTH, BUFFERPARA.BATCH_SIZE, advantages, returns
                )
            else:
                # ä¸º MLP ç”Ÿæˆéšæœºçš„æ‰¹æ¬¡ç´¢å¼•
                batch_generator = self.buffer.generate_batches()

            for batch_data in batch_generator:
                # 3. æ‰¹æ¬¡æ•°æ®å¤„ç†
                if self.use_rnn:
                    # è§£åŒ… RNN çš„åºåˆ—æ‰¹æ¬¡æ•°æ®
                    state, action_batch, old_prob, advantage, return_, initial_actor_h, initial_critic_h = batch_data
                    # å°† numpy æ•°ç»„è½¬æ¢ä¸º tensor å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
                    state = check(state).to(**ACTOR_PARA.tpdv)
                    action_batch = check(action_batch).to(**ACTOR_PARA.tpdv)
                    old_prob = check(old_prob).to(**ACTOR_PARA.tpdv)
                    advantage = check(advantage).to(**ACTOR_PARA.tpdv)
                    return_ = check(return_).to(**CRITIC_PARA.tpdv)
                    initial_actor_h = check(initial_actor_h).to(**ACTOR_PARA.tpdv)
                    initial_critic_h = check(initial_critic_h).to(**CRITIC_PARA.tpdv)
                else:
                    # å¤„ç† MLP çš„æ‰¹æ¬¡ç´¢å¼•
                    batch_indices = batch_data
                    state = check(states[batch_indices]).to(**ACTOR_PARA.tpdv)
                    action_batch = check(actions[batch_indices]).to(**ACTOR_PARA.tpdv)
                    old_prob = check(old_probs[batch_indices]).to(**ACTOR_PARA.tpdv).view(-1)
                    advantage = check(advantages[batch_indices]).to(**ACTOR_PARA.tpdv).view(-1, 1)
                    return_ = check(returns[batch_indices]).to(**CRITIC_PARA.tpdv).view(-1, 1)
                # ä»æ‰¹æ¬¡åŠ¨ä½œä¸­è§£æå‡ºè¿ç»­å’Œç¦»æ•£éƒ¨åˆ†
                u_from_buffer = action_batch[..., :CONTINUOUS_DIM]
                discrete_actions_from_buffer = {
                    'trigger': action_batch[..., CONTINUOUS_DIM],
                    'salvo_size': action_batch[..., CONTINUOUS_DIM + 1].long(), # ç±»åˆ«ç´¢å¼•éœ€è¦æ˜¯ long ç±»å‹
                    # 'intra_interval': action_batch[..., CONTINUOUS_DIM + 2].long(),
                    'num_groups': action_batch[..., CONTINUOUS_DIM + 2].long(),
                    'inter_interval': action_batch[..., CONTINUOUS_DIM + 3].long(),
                }

                # 4. Actor (ç­–ç•¥) ç½‘ç»œè®­ç»ƒ
                if self.use_rnn:
                    new_dists, _ = self.Actor(state, initial_actor_h)
                else:
                    new_dists = self.Actor(state)
                # è®¡ç®—æ–°ç­–ç•¥ä¸‹ï¼Œæ—§åŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡
                new_log_prob_cont = new_dists['continuous'].log_prob(u_from_buffer).sum(dim=-1)
                new_log_prob_disc = sum(
                    new_dists[key].log_prob(discrete_actions_from_buffer[key])
                    for key in discrete_actions_from_buffer
                )
                new_prob = new_log_prob_cont + new_log_prob_disc
                # è®¡ç®—ç­–ç•¥çš„ç†µï¼Œä»¥é¼“åŠ±æ¢ç´¢
                entropy_cont = new_dists['continuous'].entropy().sum(dim=-1)
                total_entropy = (entropy_cont + sum(
                    dist.entropy() for key, dist in new_dists.items() if key != 'continuous'
                )).mean()
                # è®¡ç®—æ–°æ—§ç­–ç•¥çš„æ¯”ç‡ (importance sampling ratio)
                log_ratio = new_prob - old_prob
                ratio = torch.exp(torch.clamp(log_ratio, -20.0, 20.0)) # clamp é˜²æ­¢æ•°å€¼æº¢å‡º
                # PPO çš„æ ¸å¿ƒï¼šClipped Surrogate Objective
                advantage_squeezed = advantage.squeeze(-1) if advantage.dim() > ratio.dim() else advantage
                surr1 = ratio * advantage_squeezed
                surr2 = torch.clamp(ratio, 1.0 - AGENTPARA.epsilon, 1.0 + AGENTPARA.epsilon) * advantage_squeezed
                # Actor çš„æŸå¤±æ˜¯è£å‰ªåçš„ç›®æ ‡å‡½æ•°çš„è´Ÿå€¼ï¼ŒåŠ ä¸Šç†µçš„æ­£åˆ™é¡¹
                actor_loss = -torch.min(surr1, surr2).mean() - AGENTPARA.entropy * total_entropy
                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                self.Actor.optim.zero_grad()
                actor_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.Actor.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
                self.Actor.optim.step()

                # 5. Critic (ä»·å€¼) ç½‘ç»œè®­ç»ƒ
                if self.use_rnn:
                    new_value, _ = self.Critic(state, initial_critic_h)
                else:
                    new_value = self.Critic(state)

                # ####################################################################
                # # <<< FINAL, DEFINITIVE FIX FOR THE BROADCASTING WARNING >>>
                # ####################################################################
                # We ensure the target `return_` tensor has the same number of dimensions
                # as the network's output `new_value`.
                # ç¡®ä¿ç›®æ ‡å€¼ `return_` å’Œç½‘ç»œè¾“å‡º `new_value` çš„ç»´åº¦ä¸€è‡´ï¼Œä»¥é¿å… PyTorch çš„å¹¿æ’­è­¦å‘Šã€‚
                # ä¾‹å¦‚ï¼Œ`new_value` å¯èƒ½æ˜¯ (B, S, 1)ï¼Œè€Œ `return_` æ˜¯ (B, S)ï¼Œè¿™ä¼šå¯¼è‡´ä¸æ˜ç¡®çš„å¹¿æ’­ã€‚
                # é€šè¿‡ unsqueeze(-1) å°† `return_` å˜ä¸º (B, S, 1)ï¼Œä½¿å…¶å½¢çŠ¶å®Œå…¨åŒ¹é…ã€‚
                if new_value.dim() > return_.dim():
                    return_ = return_.unsqueeze(-1)
                # ####################################################################
                # Critic çš„æŸå¤±æ˜¯é¢„æµ‹å€¼å’ŒçœŸå®å›æŠ¥ï¼ˆreturnsï¼‰ä¹‹é—´çš„å‡æ–¹è¯¯å·®
                critic_loss = torch.nn.functional.mse_loss(new_value, return_)
                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                self.Critic.optim.zero_grad()
                critic_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.Critic.parameters(), max_norm=1.0)
                self.Critic.optim.step()
                # è®°å½•è¯¥æ‰¹æ¬¡çš„è®­ç»ƒä¿¡æ¯
                train_info['critic_loss'].append(critic_loss.item())
                train_info['actor_loss'].append(actor_loss.item())
                train_info['dist_entropy'].append(total_entropy.item())
                train_info['entropy_cont'].append(entropy_cont.mean().item())
                train_info['adv_targ'].append(advantage.mean().item())
                train_info['ratio'].append(ratio.mean().item())
        # 6. æ¸…ç†å’Œè¿”å›
        self.buffer.clear_memory() # å®Œæˆä¸€è½®å­¦ä¹ åæ¸…ç©º Buffer
        # è®¡ç®—æ•´ä¸ª epoch çš„å¹³å‡æŒ‡æ ‡
        for key in train_info:
            train_info[key] = np.mean(train_info[key])
        # è®°å½•å½“å‰å­¦ä¹ ç‡
        train_info['actor_lr'] = self.Actor.optim.param_groups[0]['lr']
        train_info['critic_lr'] = self.Critic.optim.param_groups[0]['lr']
        self.save() # ä¿å­˜æ¨¡å‹
        return train_info

    def prep_training_rl(self):
        """å°† Actor å’Œ Critic ç½‘ç»œè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ã€‚"""
        self.Actor.train()
        self.Critic.train()

    def prep_eval_rl(self):
        """å°† Actor å’Œ Critic ç½‘ç»œè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚"""
        self.Actor.eval()
        self.Critic.eval()

    def save(self, prefix=""):
        """
        ä¿å­˜ Actor å’Œ Critic æ¨¡å‹çš„æƒé‡ã€‚
        - å¦‚æœæä¾›äº† prefixï¼Œåˆ™ä¿å­˜åˆ° 'èƒœç‡æ¨¡å‹' å­ç›®å½•ä¸­ã€‚
        - å¦åˆ™ï¼Œä¿å­˜åˆ°ä¸»è¿è¡Œç›®å½•ä¸­ã€‚
        """
        # --- 3. åˆå§‹åŒ–æ—¶åˆ›å»ºæ‰€æœ‰éœ€è¦çš„ç›®å½• (æ¨èåšæ³•) ---
        try:
            os.makedirs(self.run_save_dir, exist_ok=True)
            os.makedirs(self.win_rate_dir, exist_ok=True)
            print(f"è®­ç»ƒå­˜æ¡£ç›®å½•å·²åˆ›å»º: {self.run_save_dir}")
        except Exception as e:
            print(f"åˆ›å»ºå­˜æ¡£ç›®å½•å¤±è´¥: {e}")

        # --- 1. æ ¹æ® prefix ç¡®å®šç›®æ ‡ä¿å­˜ç›®å½• (é€»è¾‘æ›´æ¸…æ™°) ---
        if prefix:
            target_dir = self.win_rate_dir
            print(f"èƒœç‡æ¨¡å‹å°†è¢«ä¿å­˜è‡³: {target_dir}")
        else:
            target_dir = self.run_save_dir
            print(f"å¸¸è§„æ¨¡å‹å°†è¢«ä¿å­˜è‡³: {target_dir}")

        # --- 2. å¾ªç¯ä¿å­˜æ¨¡å‹ (ä»£ç æ— é‡å¤) ---
        for net_name in ['Actor', 'Critic']:
            try:
                # è·å–æ¨¡å‹å¯¹è±¡
                net_model = getattr(self, net_name)

                # æ„é€ æ–‡ä»¶å
                filename = f"{prefix}_{net_name}.pkl" if prefix else f"{net_name}.pkl"
                full_path = os.path.join(target_dir, filename)

                # ä¿å­˜æ¨¡å‹çš„çŠ¶æ€å­—å…¸
                torch.save(net_model.state_dict(), full_path)
                print(f"  - {filename} ä¿å­˜æˆåŠŸã€‚")

            except AttributeError:
                print(f"  - é”™è¯¯: æ‰¾ä¸åˆ°åä¸º '{net_name}' çš„æ¨¡å‹ã€‚")
            except Exception as e:
                print(f"  - ä¿å­˜æ¨¡å‹ {net_name} åˆ° {full_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # def save(self, prefix=""):
    #     """ä¿å­˜ Actor å’Œ Critic æ¨¡å‹çš„æƒé‡ã€‚"""
    #     try:
    #         # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    #         os.makedirs(self.run_save_dir, exist_ok=True)
    #         print(f"æ¨¡å‹å°†è¢«ä¿å­˜è‡³: {self.run_save_dir}")
    #     except Exception as e:
    #         print(f"åˆ›å»ºæ¨¡å‹æ–‡ä»¶å¤¹ {self.run_save_dir} å¤±è´¥: {e}")
    #         return
    #     # åˆ†åˆ«ä¿å­˜ Actor å’Œ Critic
    #     for net in ['Actor', 'Critic']:
    #         try:
    #             filename = f"{prefix}_{net}.pkl" if prefix else f"{net}.pkl"
    #             full_path = os.path.join(self.run_save_dir, filename)
    #             torch.save(getattr(self, net).state_dict(), full_path)
    #             print(f"  - {filename} ä¿å­˜æˆåŠŸã€‚")
    #         except Exception as e:
    #             print(f"  - ä¿å­˜æ¨¡å‹ {net} åˆ° {full_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")